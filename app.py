"""
AIçŸ¥è¯†é—®ç­”ç³»ç»Ÿ - Oracle Vector Storeç‰ˆæœ¬
"""

import streamlit as st
from utils.oracle_vector_store import OracleVectorStore
from utils.oracle_json_store import OracleJsonStore
from utils.oracle_graph_store import OracleGraphStore
from utils.oracle_property_graph import OraclePropertyGraph
from utils.medical_record_parser import MedicalRecordParser
from sentence_transformers import SentenceTransformer
import os
from dotenv import load_dotenv
import shutil
from pathlib import Path
import logging
from openai import OpenAI
import pdfplumber
import json
import datetime
import hashlib
from typing import Dict, Any, List
from decimal import Decimal
from utils.medical_graph_parser import MedicalGraphParser
from pyvis.network import Network
import streamlit.components.v1 as components
import tempfile
import networkx as nx
from collections import defaultdict
import pandas as pd
import plotly.express as px
from utils.json_cache import JsonCache
import re

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# è·å–OpenAIé…ç½®
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_API_BASE = os.getenv("OPENAI_API_BASE")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")

# è®¾ç½®æ–‡æ¡£å­˜å½•
UPLOAD_DIR = Path("uploaded_documents")
UPLOAD_DIR.mkdir(exist_ok=True)

# è®¾ç½®JSONç¼“å­˜ç›®å½•
CACHE_DIR = Path("json_cache")
CACHE_DIR.mkdir(exist_ok=True)

# ä½¿ç”¨ st.cache_resource ç¼“å­˜æ¨¡å‹ï¼Œå¹¶éšè—
@st.cache_resource(show_spinner=False)
def load_embeddings_model():
    """åŠ è½½å‘é‡åŒ–æ¨¡å‹ï¼ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼‰"""
    logger.debug("åŠ è½½å‘é‡åŒ–æ¨¡å‹")
    return SentenceTransformer('all-MiniLM-L6-v2')

# åˆå§‹åŒ–æ¨¡å‹
embeddings_model = load_embeddings_model()

def get_cache_path(file_path: str) -> Path:
    """æ ¹æ®æ–‡ä»¶è·¯å¾„ç”Ÿæˆç¼“å­˜æ–‡ä»¶è·¯å¾„"""
    # è·å–åŸå§‹æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
    original_name = Path(file_path).stem
    return CACHE_DIR / f"{original_name}.json"

def save_to_cache(file_name: str, data: dict):
    """ä¿å­˜æ•°æ®åˆ°JSONç¼“å­˜"""
    try:
        json_cache = JsonCache()
        cache_path = json_cache.get_cache_path(file_name)
        return json_cache.save_json(cache_path, data)
    except Exception as e:
        logger.error(f"ä¿å­˜åˆ°ç¼“å­˜å¤±è´¥: {str(e)}")
        return False

def load_from_cache(file_path: str) -> Dict:
    """ä»ç¼“å­˜åŠ è½½ç»“æ„åŒ–æ•°æ®"""
    cache_path = get_cache_path(file_path)
    if cache_path.exists():
        with open(cache_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        logger.info(f"ä»ç¼“å­˜åŠ è½½: {cache_path}")
        return data
    return None

def save_uploaded_file(uploaded_file):
    """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶"""
    try:
        if not uploaded_file:
            logger.error("æœªæä¾›ä¸Šä¼ æ–‡ä»¶")
            raise ValueError("æœªæä¾›ä¸Šä¼ æ–‡ä»¶")
            
        # è·å–æ–‡ä»¶åå’Œæ‰©å±•å
        file_name = uploaded_file.name
        file_ext = Path(file_name).suffix.lower()
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        allowed_extensions = {'.pdf', '.txt', '.docx'}
        if file_ext not in allowed_extensions:
            logger.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}")
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}ï¼Œä»…æ”¯æŒ {', '.join(allowed_extensions)}")
            
        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆé™åˆ¶ä¸º 10MBï¼‰
        max_size = 10 * 1024 * 1024  # 10MB in bytes
        if uploaded_file.size > max_size:
            logger.error(f"æ–‡ä»¶è¿‡å¤§: {uploaded_file.size} bytes")
            raise ValueError(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ï¼ˆæœ€å¤§ 10MBï¼‰")
            
        # æ„å»ºä¿å­˜è·¯å¾„
        save_path = UPLOAD_DIR / file_name
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ•°å­—åç¼€
        counter = 1
        while save_path.exists():
            stem = Path(file_name).stem
            new_name = f"{stem}_{counter}{file_ext}"
            save_path = UPLOAD_DIR / new_name
            counter += 1
            
        # ä¿å­˜æ–‡ä»¶
        try:
            with open(save_path, 'wb') as f:
                f.write(uploaded_file.getbuffer())
            logger.info(f"æ–‡ä»¶ä¿å­˜æˆåŠŸ: {save_path}")
            return save_path
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            if save_path.exists():
                try:
                    save_path.unlink()
                    logger.info(f"åˆ é™¤å¤±è´¥çš„æ–‡ä»¶: {save_path}")
                except Exception as del_e:
                    logger.warning(f"åˆ é™¤å¤±è´¥çš„æ–‡ä»¶æ—¶å‡ºé”™: {str(del_e)}")
            raise
            
    except Exception as e:
        logger.error(f"å¤„ç†ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None

def read_file_content(file_obj):
    """è¯»å–æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒå¤šç§æ–‡ä»¶ç±»å‹å’Œç¼–ç """
    try:
        # å¤„ç†æ–‡ä»¶è·¯å¾„
        if isinstance(file_obj, (str, Path)):
            file_path = Path(file_obj)
            if not file_path.exists():
                logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                
            file_type = file_path.suffix.lower()
            logger.info(f"å¤„ç†æ–‡ä»¶: {file_path}, ç±»å‹: {file_type}")
            
            if file_type == '.pdf':
                try:
                    with pdfplumber.open(str(file_path)) as pdf:
                        text_content = []
                        for page in pdf.pages:
                            text = page.extract_text()
                            if text:
                                text_content.append(text)
                        content = '\n'.join(text_content)
                        if not content:
                            logger.warning(f"PDF æ–‡ä»¶å†…å®¹ä¸ºç©º: {file_path}")
                            raise ValueError(f"PDF æ–‡ä»¶å†…å®¹ä¸ºç©º: {file_path}")
                        return content
                except Exception as e:
                    logger.error(f"è¯»å– PDF æ–‡ä»¶å¤±è´¥: {str(e)}")
                    raise
            else:
                # å°è¯•ä¸åŒçš„ç¼–ç è¯»å–æ–‡æœ¬æ–‡ä»¶
                encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030']
                for encoding in encodings:
                    try:
                        with open(file_path, 'r', encoding=encoding) as f:
                            content = f.read()
                            if content:
                                logger.info(f"æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç è¯»å–æ–‡ä»¶")
                                return content
                    except UnicodeDecodeError:
                        logger.debug(f"ä½¿ç”¨ {encoding} ç¼–ç è¯»å–å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç¼–ç ")
                        continue
                logger.error(f"æ— æ³•ä½¿ç”¨å·²çŸ¥ç¼–ç è¯»å–æ–‡ä»¶: {', '.join(encodings)}")
                raise ValueError(f"æ— æ³•ä½¿ç”¨å·²çŸ¥ç¼–ç è¯»å–æ–‡ä»¶: {', '.join(encodings)}")
        
        # å¤„ç†æ–‡ä»¶å¯¹è±¡
        else:
            if not hasattr(file_obj, 'read'):
                logger.error("æ— æ•ˆçš„æ–‡ä»¶å¯¹è±¡ï¼šç¼ºå°‘ read æ–¹æ³•")
                raise ValueError("æ— æ•ˆçš„æ–‡ä»¶å¯¹è±¡ï¼šç¼ºå°‘ read æ–¹æ³•")
                
            # è·å–æ–‡ä»¶ç±»å‹
            file_type = Path(file_obj.name).suffix.lower() if hasattr(file_obj, 'name') else ''
            logger.info(f"å¤„ç†æ–‡ä»¶å¯¹è±¡ï¼Œç±»å‹: {file_type}")
            
            # å¤„ç† PDF æ–‡ä»¶
            if file_type == '.pdf':
                try:
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_file:
                        temp_file.write(file_obj.read())
                        temp_path = temp_file.name
                        logger.debug(f"åˆ›å»ºä¸´æ—¶æ–‡ä»¶: {temp_path}")
                    
                    try:
                        with pdfplumber.open(temp_path) as pdf:
                            text_content = []
                            for page in pdf.pages:
                                text = page.extract_text()
                                if text:
                                    text_content.append(text)
                            content = '\n'.join(text_content)
                            if not content:
                                logger.warning("PDF æ–‡ä»¶å†…å®¹ä¸ºç©º")
                                raise ValueError("PDF æ–‡ä»¶å†…å®¹ä¸ºç©º")
                            return content
                    finally:
                        try:
                            os.unlink(temp_path)
                            logger.debug(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_path}")
                        except Exception as e:
                            logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")
                except Exception as e:
                    logger.error(f"å¤„ç† PDF æ–‡ä»¶å¯¹è±¡å¤±è´¥: {str(e)}")
                    raise
            
            # å¤„ç†å…¶ä»–æ–‡ä»¶
            else:
                try:
                    content = file_obj.read()
                    if isinstance(content, bytes):
                        # å°è¯•ä¸åŒçš„ç¼–ç è§£ç 
                        encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030']
                        for encoding in encodings:
                            try:
                                decoded = content.decode(encoding)
                                logger.info(f"æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç è§£ç å†…å®¹")
                                return decoded
                            except UnicodeDecodeError:
                                logger.debug(f"ä½¿ç”¨ {encoding} ç¼–ç è§£ç å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç¼–ç ")
                                continue
                        logger.error(f"æ— æ³•ä½¿ç”¨å·²çŸ¥ç¼–ç è§£ç æ–‡ä»¶å†…å®¹: {', '.join(encodings)}")
                        raise ValueError(f"æ— æ³•ä½¿ç”¨å·²çŸ¥ç¼–ç è§£ç æ–‡ä»¶å†…å®¹: {', '.join(encodings)}")
                    return content
                except Exception as e:
                    logger.error(f"è¯»å–æ–‡ä»¶å¯¹è±¡å¤±è´¥: {str(e)}")
                    raise
                
    except Exception as e:
        logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
        raise

def get_uploaded_files():
    """è·å–å·²ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨"""
    return list(UPLOAD_DIR.glob("*.*"))

def vectorize_document(file_path):
    """å‘é‡åŒ–æ–‡æ¡£
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ– Path å¯¹è±¡
        
    Returns:
        bool: å‘é‡åŒ–æ˜¯å¦æˆåŠŸ
    """
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        logger.info(f"å¼€å§‹å‘é‡åŒ–æ–‡æ¡£: {file_path}")
        content = read_file_content(file_path)
        
        if not content:
            logger.error("æ–‡æ¡£å†…å®¹ä¸ºç©º")
            return False
            
        # ä½¿ç”¨å·²åŠ è½½çš„æ¨¡å‹è¿›è¡Œå‘é‡åŒ–
        try:
            # å°†æ–‡æ¡£å†…å®¹åˆ†å‰²æˆè¾ƒå°çš„å—
            chunks = split_text_into_chunks(content)
            if not chunks:
                logger.error("æ–‡æ¡£åˆ†å—å¤±è´¥")
                return False
                
            # å¯¹æ¯ä¸ªå—è¿›è¡Œå‘é‡åŒ–
            vectors = []
            documents = []
            for i, chunk in enumerate(chunks):
                try:
                    # å‘é‡åŒ–æ–‡æœ¬å—
                    vector = embeddings_model.encode([chunk])[0]
                    vectors.append(vector)
                    
                    # å‡†å¤‡æ–‡æ¡£ä¿¡æ¯
                    doc_info = {
                        "file_path": str(file_path),
                        "content": chunk,
                        "chunk_index": i
                    }
                    documents.append(doc_info)
                    
                except Exception as e:
                    logger.error(f"å¤„ç†æ–‡æœ¬å— {i} å¤±è´¥: {str(e)}")
                    continue
            
            if not vectors:
                logger.error("æ²¡æœ‰æˆåŠŸå‘é‡åŒ–çš„æ–‡æœ¬å—")
                return False
                
            # ä¿å­˜å‘é‡åˆ°æ•°æ®åº“
            with OracleVectorStore() as vector_store:
                vector_store.add_vectors(vectors, documents)
                logger.info(f"æˆåŠŸä¿å­˜ {len(vectors)} ä¸ªå‘é‡åˆ°æ•°æ®åº“")
                
            return True
            
        except Exception as e:
            logger.error(f"å‘é‡åŒ–è¿‡ç¨‹å¤±è´¥: {str(e)}")
            return False
            
    except Exception as e:
        logger.error(f"å‘é‡åŒ–æ–‡æ¡£å¤±è´¥: {str(e)}")
        return False
        
def split_text_into_chunks(text, chunk_size=1000, overlap=100):
    """å°†æ–‡æœ¬åˆ†å‰²æˆè¾ƒå°çš„å—
    
    Args:
        text: è¦åˆ†å‰²çš„æ–‡æœ¬
        chunk_size: æ¯ä¸ªå—çš„æœ€å¤§å­—ç¬¦æ•°
        overlap: ç›¸é‚»å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°
        
    Returns:
        list: æ–‡æœ¬å—åˆ—è¡¨
    """
    try:
        if not text:
            return []
            
        # æŒ‰å¥å­åˆ†å‰²æ–‡æœ¬
        sentences = re.split('[ã€‚ï¼ï¼Ÿ.!?]', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        chunks = []
        current_chunk = []
        current_length = 0
        
        for sentence in sentences:
            sentence_length = len(sentence)
            
            # å¦‚æœå•ä¸ªå¥å­è¶…è¿‡å—å¤§å°ï¼Œåˆ™æŒ‰å­—ç¬¦åˆ†å‰²
            if sentence_length > chunk_size:
                if current_chunk:
                    chunks.append(''.join(current_chunk))
                    current_chunk = []
                    current_length = 0
                
                # åˆ†å‰²é•¿å¥å­
                for i in range(0, sentence_length, chunk_size - overlap):
                    chunk = sentence[i:i + chunk_size]
                    if chunk:
                        chunks.append(chunk)
                continue
            
            # å¦‚æœæ·»åŠ å½“å‰å¥å­ä¼šè¶…è¿‡å—å¤§å°ï¼Œä¿å­˜å½“å‰å—å¹¶å¼€å§‹æ–°å—
            if current_length + sentence_length > chunk_size:
                if current_chunk:
                    chunks.append(''.join(current_chunk))
                current_chunk = [sentence]
                current_length = sentence_length
            else:
                current_chunk.append(sentence)
                current_length += sentence_length
        
        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunks.append(''.join(current_chunk))
        
        return chunks
        
    except Exception as e:
        logger.error(f"åˆ†å‰²æ–‡æœ¬å¤±è´¥: {str(e)}")
        return []

def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
    try:
        with OracleJsonStore() as json_store:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            check_table_sql = """
            SELECT table_name 
            FROM user_tables 
            WHERE table_name = 'DOCUMENT_JSON'
            """
            result = json_store.execute_search(check_table_sql)
            table_exists = len(result) > 0 if result else False
            
            if not table_exists:
                # åˆ›å»ºç»“æ„åŒ–æ–‡æ¡£è¡¨
                create_json_table_sql = """
                CREATE TABLE DOCUMENT_JSON (
                    id NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    doc_info VARCHAR2(500),
                    doc_json JSON,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
                """
                json_store.execute_sql(create_json_table_sql)
                logger.info("æˆåŠŸåˆ›å»º DOCUMENT_JSON è¡¨")
            else:
                logger.debug("DOCUMENT_JSON è¡¨å·²å­˜åœ¨ï¼Œç»§ç»­ä½¿ç”¨")

    except Exception as e:
        logger.error(f"åˆå§‹åŒ–æ•°æ®åº“å¤±è´¥: {str(e)}")
        st.error(f"åˆå§‹åŒ–æ•°æ®åº“å¤±è´¥: {str(e)}")
        raise

class MedicalRecordParser:
    def __init__(self):
        self.client = OpenAI(
            api_key=OPENAI_API_KEY,
            base_url=OPENAI_API_BASE
        )

    def parse_medical_record(self, text: str, doc_info: str) -> Dict[str, Any]:
        """è§£æåŒ»ç–—è®°å½•æ–‡æœ¬ï¼Œç”Ÿæˆç»“æ„åŒ–JSONæ•°æ®å’ŒSQLæ’å…¥è¯­å¥"""
        try:
            prompt = f"""è¯·å°†ä»¥ä¸‹ç—…å†å†…å®¹ç»“æ„åŒ–ä¸ºJSONæ ¼å¼ï¼Œå¹¶ç”Ÿæˆå¯¹åº”çš„SQLæ’å…¥è¯­å¥ã€‚

ç—…å†å†…å®¹ï¼š
{text}

è¦æ±‚ï¼š
1. JSONç»“æ„ï¼š
{{
    "æ‚£è€…å§“å": "æŸæŸï¼ˆä¿æŠ¤éšç§ï¼‰",
    "æ€§åˆ«": "æ€§åˆ«",
    "å¹´é¾„": "æ•°å­—",
    "å…¥é™¢æ—¥æœŸ": "YYYY-MM-DD",
    "å‡ºé™¢æ—¥æœŸ": "YYYY-MM-DD",
    "ä¸»è¯‰": "ä¸»è¦ç—‡çŠ¶",
    "ç°ç—…å²": ["ç—‡çŠ¶1", "ç—‡çŠ¶2"],
    "å…¥è¯Š": ["è¯Šæ–­1", "è¯Šæ–­2"],
    "å‡ºé™¢è¯Š": ["æ–­1", "è¯Šæ–­2"],
    "ç”Ÿå‘½ä½“å¾": {{
        "ä½“æ¸©": "åŒ…å«å•ä½",
        "è¡€å‹": "åŒ…å«å•ä½"
    }},
    "ç”ŸåŒ–æŒ‡æ ‡": {{
        "æŒ‡æ ‡å": "å€¼å’Œå•ä½ï¼Œå¼‚å¸¸æ ‡â†‘â†“"
    }},
    "è¯Šç–—ç»è¿‡": "æ²»ç–—è¿‡ç¨‹æè¿°",
    "å‡ºé™¢åŒ»å˜±": ["åŒ»å˜±1", "åŒ»å˜±2"]
}}

2. SQLè¦æ±‚ï¼š
- è¡¨åï¼šDOCUMENT_JSON
- å­—æ®µï¼š(id NUMBERè‡ªå¢, doc_info VARCHAR2(500), doc_json JSON)
- doc_infoå€¼ï¼š{doc_info}
- ä½¿ç”¨JSON_OBJECTæˆ–FORMAT JSONè¯­æ³•

è¯·è¿”å›ï¼š
{{
    "structured_data": JSONæ ¼å¼çš„ç—…å†æ•°æ®,
    "sql_statement": Oracleæ’å…¥è¯­å¥
}}"""

            response = self.client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "ä½ ç–—æ•°æ®ç»“æ„åŒ–ä¸“å®¶ï¼Œæ“…é•¿è§£æç—…å†æ–‡æœ¬å¹¶ç”Ÿæˆè§„èŒƒçš„JSONå’ŒSQL"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
            )

            # è§£æè¿”å›çš„JSON
            result = json.loads(response.choices[0].message.content)
            
            # éªŒè¯ç»“æœæ ¼å¼
            if not isinstance(result, dict) or 'structured_data' not in result or 'sql_statement' not in result:
                raise ValueError("GPTè¿”å›æ•°æ®æ ¼å¼ä¸æ­£ç¡®")

            # æ·»åŠ å…ƒæ•°æ®
            if 'metadata' not in result['structured_data']:
                result['structured_data']['metadata'] = {}
            result['structured_data']['metadata'].update({
                'import_time': datetime.datetime.now().isoformat(),
                'source_type': 'text',
                'last_updated': datetime.datetime.now().isoformat()
            })

            return result

        except Exception as e:
            logger.error(f"è§£æåŒ»ç–—è®°å½•å¤±è´¥: {str(e)}")
            return {"error": f"è§£æå¤±è´¥: {str(e)}"}

def parse_document_to_json(file_obj):
    """è§£æåŒ»ç–—æ–‡æ¡£å¹¶ä¿å­˜åˆ°æ•°æ®åº“"""
    try:
        # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        file_name = Path(file_obj.name).stem
        
        # æ£€æŸ¥ç¼“å­˜
        json_cache = JsonCache()
        cache_path = json_cache.get_cache_path(file_name)
        
        # å¦‚æœç¼“å­˜å­˜åœ¨ï¼Œç›´æ¥ä»ç¼“å­˜åŠ è½½
        if os.path.exists(cache_path):
            try:
                cached_data = json_cache.load_json(cache_path)
                logger.info(f"ä»ç¼“å­˜åŠ è½½æ–‡æ¡£: {file_name}")
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                with OracleJsonStore() as json_store:
                    json_store.add_document(file_obj.name, cached_data)
                    logger.info(f"ä¿å­˜æ–‡æ¡£åˆ°æ•°æ®åº“: {file_name}")
                
                return {"success": True, "message": "ä»ç¼“å­˜åŠ è½½å¹¶ä¿å­˜åˆ°æ•°æ®åº“æˆåŠŸ"}
            except Exception as e:
                logger.error(f"ä»ç¼“å­˜åŠ è½½å¤±è´¥: {str(e)}")
                # ç»§ç»­å°è¯•é‡æ–°è§£ææ–‡æ¡£
        
        # è¯»å–æ–‡æ¡£å†…å®¹
        content = read_file_content(file_obj)
        if not content:
            raise ValueError("æ— æ³•è¯»å–æ–‡æ¡£å†…å®¹")
            
        # ä½¿ç”¨ GPT è§£ææ–‡æ¡£
        client = OpenAI(
            api_key=OPENAI_API_KEY,
            base_url=OPENAI_API_BASE
        )
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""
        è¯·è§£æä»¥ä¸‹åŒ»ç–—æ–‡æ¡£ï¼Œæå–å…³é”®ä¿¡æ¯å¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š

        {content}

        è¯·æå–ä»¥ä¸‹ä¿¡æ¯ï¼š
        1. æ‚£è€…åŸºæœ¬ä¿¡æ¯ï¼ˆå§“åã€æ€§åˆ«ã€å¹´é¾„ç­‰ï¼‰
        2. ä¸»è¯‰
        3. ç°ç—…å²
        4. å…¥é™¢è¯Šæ–­å’Œå‡ºé™¢è¯Šæ–­
        5. ç”Ÿå‘½ä½“å¾
        6. ç”ŸåŒ–æŒ‡æ ‡
        7. è¯Šç–—ç»è¿‡
        8. å‡ºé™¢åŒ»å˜±

        è¿”å›æ ¼å¼ç¤ºä¾‹ï¼š
        {{
            "æ‚£è€…å§“å": "xxx",
            "æ€§åˆ«": "ç”·/å¥³",
            "å¹´é¾„": "xxå²",
            "ä¸»è¯‰": "xxxx",
            "ç°ç—…å²": ["ç—‡çŠ¶1", "ç—‡çŠ¶2"],
            "å…¥é™¢è¯Šæ–­": ["è¯Šæ–­1", "è¯Šæ–­2"],
            "å‡ºé™¢è¯Šæ–­": ["è¯Šæ–­1", "è¯Šæ–­2"],
            "ç”Ÿå‘½ä½“å¾": {{
                "ä½“æ¸©": "xxâ„ƒ",
                "è¡€å‹": "xx/xxmmHg"
            }},
            "ç”ŸåŒ–æŒ‡æ ‡": {{
                "ç™½ç»†èƒ": "xxÃ—10^9/L",
                "è¡€çº¢è›‹ç™½": "xx g/L"
            }},
            "è¯Šç–—ç»è¿‡": "xxxx",
            "å‡ºé™¢åŒ»å˜±": ["åŒ»å˜±1", "åŒ»å˜±2"]
        }}

        æ³¨æ„ï¼š
        1. ä¿æŒæ•°æ®ç»“æ„çš„ä¸€è‡´æ€§
        2. å¯¹äºç¼ºå¤±çš„ä¿¡æ¯ä½¿ç”¨ç©ºå€¼æˆ–ç©ºåˆ—è¡¨
        3. ç¡®ä¿è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼
        """
        
        # è°ƒç”¨ GPT è§£ææ–‡æ¡£
        response = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—æ–‡æ¡£è§£æåŠ©æ‰‹ï¼Œæ“…é•¿ä»åŒ»ç–—æ–‡æ¡£ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,  # ä½¿ç”¨è¾ƒä½çš„æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„è¾“å‡º
        )
        
        # è§£æ GPT è¿”å›çš„ç»“æœ
        result = response.choices[0].message.content
        if not result:
            raise ValueError("GPT æœªè¿”å›è§£æç»“æœ")
            
        try:
            parsed_data = json.loads(result)
            if not isinstance(parsed_data, dict):
                raise ValueError("è§£æç»“æœä¸æ˜¯æœ‰æ•ˆçš„ JSON å¯¹è±¡")
                
            # ä¿å­˜åˆ°ç¼“å­˜
            if json_cache.save_json(cache_path, parsed_data):
                logger.info(f"ä¿å­˜åˆ°ç¼“å­˜æˆåŠŸ: {cache_path}")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            with OracleJsonStore() as json_store:
                json_store.add_document(file_obj.name, parsed_data)
                logger.info(f"ä¿å­˜æ–‡æ¡£åˆ°æ•°æ®åº“: {file_name}")
            
            return {"success": True, "message": "æ–‡æ¡£è§£æå¹¶ä¿å­˜æˆåŠŸ"}
            
        except json.JSONDecodeError as e:
            logger.error(f"è§£æ GPT è¿”å›çš„ JSON å¤±è´¥: {str(e)}")
            raise ValueError("è§£æ GPT è¿”å›çš„ JSON å¤±è´¥")
            
    except Exception as e:
        logger.error(f"è§£ææ–‡æ¡£å¤±è´¥: {str(e)}")
        return {"error": f"è§£ææ–‡æ¡£å¤±è´¥: {str(e)}"}

def search_similar_documents(query: str, top_k: int = 3):
    """å‘é‡æœç´¢å¹¶ä½¿ç”¨ GPT åˆ†ææœ€ç›¸å…³çš„æ–‡æ¡£"""
    try:
        # 1. å‘é‡æœç´¢
        vector = embeddings_model.encode([query])[0]
        with OracleVectorStore() as vector_store:
            results = vector_store.search_vectors([vector], top_k=top_k)
        
        if not results:
            return []

        # 2. ä½¿ç”¨ GPT åˆ†ææœ€ç›¸å…³çš„æ–‡æ¡£
        best_match = results[0]  # å–ç›¸ä¼¼åº¦æœ€é«˜çš„æ–‡æ¡£
        
        prompt = f"""
        åŸºäºä»¥ä¸‹åŒ»ç–—æ–‡æ¡£å†…å®¹ï¼Œå›ç­”é—®é¢˜ï¼š{query}

        æ–‡æ¡£å†…å®¹ï¼š
        {best_match['content']}

        è¯·æä¾›è¯¦ç»†ä¸“ä¸šåˆ†æå’Œç­”æ¡ˆã€‚å¦‚æœæ–‡æ¡£å†…å®¹ä¸é—®é¢˜æ— å…³ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºã€‚
        """

        # ä½¿ç”¨æ–° OpenAI API
        client = OpenAI(
            api_key=OPENAI_API_KEY,
            base_url=OPENAI_API_BASE
        )
        
        response = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æåŒ»ç–—æ–‡æ¡£å¹¶ä¾›å‡†ç¡®çš„ç­”æ¡ˆã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
        )

        # 3. å°† GPT åˆ†æç»“æœæ·»åŠ åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£ä¸­
        best_match['gpt_analysis'] = response.choices[0].message.content
        
        # è¿”å›æ‰€æœ‰æ£€ç´¢ç»“æœï¼Œä½†åªæœ‰ç›¸å…³çš„æ–‡åŒ…å« GPT åˆ†æ
        return results

    except Exception as e:
        logger.error(f"æœç´¢æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return []

def analyze_query_with_gpt(query_text):
    """ä½¿ç”¨ GPT åˆ†ææŸ¥è¯¢æ„å›¾å¹¶ç”ŸæˆæŸ¥è¯¢æ¡ä»¶"""
    try:
        client = OpenAI(
            api_key=OPENAI_API_KEY,
            base_url=OPENAI_API_BASE
        )
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""
        åˆ†æä»¥ä¸‹åŒ»ç–—æŸ¥è¯¢ï¼Œç”Ÿæˆ Oracle JSON æŸ¥è¯¢æ¡ä»¶ï¼š{query_text}

        æ–‡æ¡£ç»“æ„ç¤ºä¾‹ï¼š
        {{
            "æ‚£è€…å§“å": "å¼ æŸæŸ",
            "ä¸»è¯‰": "å¤´ç—›ã€å‘çƒ­3å¤©",
            "ç°ç—…å²": ["å‘çƒ­", "å¤´ç—›", "å’³å—½"],
            "å…¥é™¢è¯Šæ–­": ["ä¸Šå‘¼å¸é“æ„ŸæŸ“", "ç—…æ¯’æ€§æ„Ÿå†’"],
            "å‡ºé™¢è¯Šæ–­": ["ç—…æ¯’æ€§æ„Ÿå†’"],
            "ç”Ÿå‘½ä½“å¾": {{
                "ä½“æ¸©": "38.5â„ƒ",
                "è¡€å‹": "120/80mmHg"
            }},
            "ç”ŸåŒ–æŒ‡æ ‡": {{
                "ç™½ç»†èƒ": "10.5Ã—10^9/L",
                "è¡€çº¢è›‹ç™½": "125g/L"
            }}
        }}

        ç¤ºä¾‹æŸ¥è¯¢å’Œå¯¹åº”çš„æ¡ä»¶ï¼š
        1. æŸ¥è¯¢æ‚£è€…å¼ æŸæŸçš„ä¿¡æ¯
           {{"conditions": ["JSON_EXISTS(doc_json, '$.æ‚£è€…å§“å?(@ == \"å¼ æŸæŸ\")')"]}}

        2. æŸ¥è¯¢æ‚£è€…å¼ æŸæŸçš„ä¸»è¯‰
           {{"conditions": ["JSON_EXISTS(doc_json, '$.æ‚£è€…å§“å?(@ == \"å¼ æŸæŸ\")') AND JSON_EXISTS(doc_json, '$.ä¸»è¯‰')" ]}}

        3. æŸ¥è¯¢ä¸»è¯‰åŒ…å«å¤´ç—›çš„ç—…ä¾‹
           {{"conditions": ["JSON_EXISTS(doc_json, '$.ä¸»è¯‰?(@ like_regex \"å¤´ç—›\" flag \"i\")')"]}}

        4. æŸ¥è¯¢ä½“æ¸©è¶…è¿‡38åº¦çš„ç—…ä¾‹
           {{"conditions": ["JSON_EXISTS(doc_json, '$.ç”Ÿå‘½ä½“å¾.ä½“æ¸©?(@ like_regex \"3[8-9]|4[0-9]\" flag \"i\")')"]}}

        è¯·åˆ†ææŸ¥è¯¢å¹¶ç”Ÿæˆå‡†ç¡®çš„ Oracle JSON æŸ¥è¯¢æ¡ä»¶ã€‚æ³¨æ„ï¼š
        1. ç¡®ä¿è·¯å¾„ä¸æ–‡æ¡£ç»“æ„åŒ¹é…
        2. ä½¿ç”¨æ­£ç¡®çš„ JSON_EXISTS è¯­æ³•ï¼Œ@ å’Œ == ä¹‹é—´éœ€è¦æœ‰ç©ºæ ¼
        3. å¯¹äºæ–‡æœ¬åŒ¹é…ï¼Œä½¿ç”¨ like_regex å¹¶æ·»åŠ  flag "i" å®ç°ä¸åŒºåˆ†å¤§å°å†™
        4. å¯¹äºæ•°å€¼æ¯”è¾ƒï¼Œä½¿ç”¨é€‚å½“çš„æ¯”è¾ƒè¿ç®—ç¬¦
        5. æŸ¥è¯¢ç‰¹å®šæ‚£è€…çš„ä¿¡æ¯æ—¶ï¼Œéœ€è¦å…ˆåŒ¹é…æ‚£è€…å§“å
        
        è¯·ç›´æ¥è¿”å› JSON æ ¼å¼çš„ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡æœ¬ã€‚
        """
        
        # è°ƒç”¨ GPT åˆ†ææŸ¥è¯¢
        response = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿å°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºæ•°æ®åº“æŸ¥è¯¢æ¡ä»¶ã€‚è¯·ç›´æ¥è¿”å› JSON æ ¼å¼çš„ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡æœ¬ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,  # ä½¿ç”¨è¾ƒä½çš„æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„è¾“å‡º
            response_format={"type": "json_object"}  # æŒ‡å®šè¿”å› JSON æ ¼å¼
        )
        
        # è§£æ GPT è¿”å›çš„ç»“æœ
        result = response.choices[0].message.content
        if not result:
            logger.warning("GPT æœªè¿”å›æœ‰æ•ˆçš„åˆ†æç»“æœ")
            return {"conditions": []}
            
        try:
            # å°è¯•è§£æ JSON
            analysis_result = json.loads(result)
            if not isinstance(analysis_result, dict) or 'conditions' not in analysis_result:
                logger.warning(f"GPT è¿”å›çš„ç»“æœæ ¼å¼ä¸æ­£ç¡®: {result}")
                return {"conditions": []}
                
            return analysis_result
            
        except json.JSONDecodeError as e:
            logger.error(f"è§£æ GPT è¿”å›çš„ JSON å¤±è´¥: {str(e)}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„æŸ¥è¯¢æ¡ä»¶
            return {"conditions": []}
            
    except Exception as e:
        logger.error(f"åˆ†ææŸ¥è¯¢å¤±è´¥: {str(e)}")
        return {"conditions": []}

# é…å¸¸é‡
TOP_K = 5  # æœç´¢ç»“æœè¿”å›çš„æœ€å¤§æ•°é‡

def normalize_medical_term(query_text):
    """ä½¿ç”¨ GPT å°†ç”¨è¯¢çš„æ ‡åç§°æ ‡å‡†åŒ–"""
    try:
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'), base_url=os.getenv('OPENAI_API_BASE'))
        
        messages = [
            {"role": "system", "content": """ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—æŒ‡æ ‡åç§°æ ‡å‡†åŒ–ä¸“å®¶
è¯·ç”¨ä¸­çš„æŒ‡æ ‡åç§°ä¸ºæ ‡çš„ç–—æ ‡ç§°

è§„
1. æŸ¥è¯¢ä¸­åŒ…å«æŸä¸ªæ£€éªŒæŒ‡æ ‡çš„åŒä¹‰è¯æˆ–è¿‘ä¹‰è¯ï¼Œè¿”å›æ ‡å‡†åç§°
2. å¦‚æœä¸ç¡®å®šï¼Œè¿”å›åŸå§‹è¯è¯­
3. è¿”å›æ ¼å¼ä¸º JSONï¼š{"standard_term": "æ ‡å‡†åç§°"}

ç¤ºï¼š
è¾“å…¥ï¼š"æ·‹å·´ç»†èƒæ¯”ä¾‹"
è¾“å‡ºï¼š{"standard_term": "æ·‹å·´ç»†èƒç™¾åˆ†æ¯”"}

è¾“å…¥ï¼š"ç™½ç»†èƒè®¡æ•°"
è¾“å‡ºï¼š{"standard_term": "èƒ"}

è¾“å…¥ï¼š"è¡€çº¢è›‹ç™½å«é‡"
è¾“å‡ºï¼š{"standard_term": "è¡€çº¢è›‹ç™½"}"""},
            {"role": "user", "content": query_text}
        ]
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.1
        )
        
        result = json.loads(response.choices[0].message.content)
        return result.get('standard_term', query_text)
        
    except Exception as e:
        logger.error(f"æŒ‡æ ‡åç§°æ ‡å‡†åŒ–: {str(e)}")
        return query_text

def search_documents(query_text):
    """åŸºäºGPTç”Ÿæˆçš„æŸ¥è¯¢æ¡ä»¶æœç´¢æ–‡æ¡£ï¼Œæ”¯æŒç»“æ„åŒ–æ•°æ®æœç´¢"""
    try:
        # ä½¿ç”¨GPTåˆ†ææŸ¥è¯¢æ„å›¾å¹¶ç”ŸæˆæŸ¥è¯¢æ¡ä»¶
        analysis_result = analyze_query_with_gpt(query_text)
        logger.info(f"GPTåˆ†æç»“æœ: {json.dumps(analysis_result, ensure_ascii=False)}")
        
        if not analysis_result or 'conditions' not in analysis_result:
            logger.error("GPTåˆ†æç»“æœæ ¼å¼é”™è¯¯")
            return []
            
        # ä½¿ç”¨GPTç”Ÿæˆçš„æ¡ä»¶æ„å»ºæŸ¥è¯¢
        conditions = analysis_result.get('conditions', [])
        json_where = " OR ".join(conditions) if conditions else "1=1"
        
        # æ„å»ºå®Œæ•´çš„æŸ¥è¯¢è¯­å¥
        query = f"""
        SELECT doc_info, doc_json
        FROM DOCUMENT_JSON d
        WHERE {json_where}
        ORDER BY id DESC
        FETCH FIRST :1 ROWS ONLY
        """
        
        # æ‰§è¡ŒæŸ¥è¯¢
        with OracleJsonStore() as json_store:
            results = json_store.execute_search(query, [TOP_K])
            if not results:
                logger.info("æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡æ¡£")
                return []
            
            # å¤„ç†ç»“æœ
            processed_results = []
            for result in results:
                try:
                    if not isinstance(result, dict) or 'doc_info' not in result or 'doc_json' not in result:
                        continue
                    
                    doc_json = result['doc_json']
                    if hasattr(doc_json, 'read'):
                        doc_json = json.loads(doc_json.read())
                    
                    if not isinstance(doc_json, dict):
                        continue
                    
                    processed_results.append({
                        'doc_info': result['doc_info'],
                        'doc_json': doc_json
                    })
                except Exception as e:
                    logger.error(f"å¤„ç†æœç´¢ç»“æœæ—¶å‡ºé”™: {str(e)}")
                    continue
            
            return processed_results
            
    except Exception as e:
        logger.error(f"æœç´¢æ–‡æ¡£å¤±è´¥: {str(e)}")
        return []

class DecimalEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, Decimal):
            return str(obj)
        return super(DecimalEncoder, self).default(obj)

def generate_answer(query_text, doc_json):
    """æ ¹æ®æŸ¥è¯¢å’Œæ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ"""
    try:
        # ä½¿ç”¨ GPT åˆ†ææŸ¥è¯¢å¹¶ç”Ÿæˆç­”æ¡ˆ
        client = OpenAI(
            api_key=OPENAI_API_KEY,
            base_url=OPENAI_API_BASE
        )
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""
        åŸºäºä»¥ä¸‹ç»“æ„åŒ–åŒ»ç–—æ•°æ®ï¼Œå›ç­”é—®é¢˜ï¼š{query_text}

        æ–‡æ¡£æ•°æ®ï¼š
        {json.dumps(doc_json, ensure_ascii=False, indent=2, cls=DecimalEncoder)}

        è¯·æä¾›è¯¦ç»†ä¸“ä¸šçš„åˆ†æå’Œç­”æ¡ˆã€‚å¦‚æœæ•°æ®ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºã€‚
        """
        
        # è°ƒç”¨ GPT ç”Ÿæˆç­”æ¡ˆ
        response = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æåŒ»ç–—æ•°æ®å¹¶æä¾›å‡†ç¡®çš„ç­”æ¡ˆã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
        )
        
        # è·å–ç”Ÿæˆçš„ç­”æ¡ˆ
        answer = response.choices[0].message.content
        if not answer:
            logger.warning("GPT æœªç”Ÿæˆæœ‰æ•ˆç­”æ¡ˆ")
            return None
            
        return answer
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}")
        return None

def display_search_results(query_text, results):
    """æ˜¾ç¤ºæœç´¢ç»“æœ"""
    if not results:
        st.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
        return
        
    try:
        # å°è¯•ç”Ÿæˆç²¾ç¡®ç­”æ¡ˆ
        answer = generate_answer(query_text, results[0]['doc_json'])
        if answer:
            st.success(answer)
        else:
            st.warning("æ— æ³•ç”Ÿæˆç­”æ¡ˆ")
            
        # æ˜¾ç¤ºæ‰€æœ‰åŒ¹é…çš„æ–‡æ¡£
        st.subheader(f"ğŸ“„ åŒ¹é…çš„æ–‡æ¡£ ({len(results)} ä¸ª)")
        for result in results:
            try:
                doc_info = result['doc_info']
                data = result['doc_json']
                patient_name = data.get("æ‚£è€…å§“å", Path(doc_info).stem)
                
                with st.expander(f"ğŸ“‹ {patient_name}", expanded=False):
                    # åˆ›å»ºæ ‡ç­¾é¡µ
                    tabs = st.tabs([
                        "åŸºæœ¬ä¿¡æ¯", "ä¸»è¯‰ä¸è¯Šæ–­", "ç°ç—…å²", 
                        "ç”Ÿå‘½ä½“å¾", "ç”ŸåŒ–æŒ‡æ ‡", "è¯Šç–—ç»è¿‡"
                    ])
                    
                    with tabs[0]:
                        if "åŸºæœ¬ä¿¡æ¯" in data:
                            st.json(data["åŸºæœ¬ä¿¡æ¯"])
                        else:
                            st.info("æœªè®°å½•åŸºæœ¬ä¿¡æ¯")
                    
                    with tabs[1]:
                        st.markdown("**ä¸»è¯‰**")
                        st.write(data.get("ä¸»è¯‰", "æœªè®°å½•"))
                        col1, col2 = st.columns(2)
                        with col1:
                            st.markdown("**å…¥é™¢è¯Šæ–­**")
                            for diag in data.get("å…¥é™¢è¯Šæ–­", []):
                                st.write(f"- {diag}")
                        with col2:
                            st.markdown("**å‡ºé™¢è¯Šæ–­**")
                            for diag in data.get("å‡ºé™¢è¯Šæ–­", []):
                                st.write(f"- {diag}")
                    
                    with tabs[2]:
                        st.markdown("**ç°ç—…å²**")
                        for item in data.get("ç°ç—…å²", []):
                            st.write(f"- {item}")
                    
                    with tabs[3]:
                        if "ç”Ÿå‘½ä½“å¾" in data:
                            st.json(data["ç”Ÿå‘½ä½“å¾"])
                        else:
                            st.info("æœªè®°å½•ç”Ÿå‘½ä½“å¾")
                    
                    with tabs[4]:
                        if "ç”ŸåŒ–æŒ‡æ ‡" in data:
                            st.json(data["ç”ŸåŒ–æŒ‡æ ‡"])
                        else:
                            st.info("æœªè®°å½•ç”ŸåŒ–æŒ‡æ ‡")
                    
                    with tabs[5]:
                        st.markdown("**è¯Šç–—ç»è¿‡**")
                        st.write(data.get("è¯Šç–—ç»è¿‡", "æœªè®°å½•"))
                        if "å‡ºé™¢åŒ»å˜±" in data:
                            st.markdown("**å‡ºé™¢åŒ»å˜±**")
                            for advice in data["å‡ºé™¢åŒ»å˜±"]:
                                st.write(f"- {advice}")
                                
            except Exception as e:
                logger.error(f"æ˜¾ç¤ºæ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
                continue
                
    except Exception as e:
        logger.error(f"æ˜¾ç¤ºæœç´¢ç»“æœæ—¶å‡ºé”™: {str(e)}")
        st.error("æ˜¾ç¤ºæœç´¢ç»“æœæ—¶å‡ºç°é”™è¯¯")

def get_patient_metadata(patient_name: str) -> Dict[str, Any]:
    """è·å–æ‚£è€…çš„å®é™…æ•°æ®ç»“æ„"""
    try:
        with OracleGraphStore() as graph_store:
            patient_info = graph_store.get_patient_info(patient_name)
            if not patient_info:
                return {}
            return patient_info
    except Exception as e:
        logger.error(f"è·å–æ‚£è€…å…ƒæ•°æ®å¤±è´¥: {str(e)}")
        return {}

def analyze_graph_query(query_text: str) -> Dict[str, Any]:
    """ä½¿ç”¨å¤§æ¨¡å‹åˆ†æå›¾æ•°æ®æŸ¥è¯¢æ„å›¾"""
    try:
        # ä»æŸ¥è¯¢æ–‡æœ¬ä¸­æå–æ‚£è€…å§“å
        patient_name = None
        for name in ["é©¬æŸæŸ", "å‘¨æŸæŸ", "åˆ˜æŸæŸ", "è’²æŸæŸ", "æ¨æŸæŸ"]:
            if name in query_text:
                patient_name = name
                break
        
        if not patient_name:
            logger.warning("æœªèƒ½ä»æŸ¥è¯¢ä¸­è¯†åˆ«å‡ºæ‚£è€…å§“å")
            return {
                "query_type": "åŸºæœ¬ä¿¡æ¯",
                "field": "all",
                "patient_name": None,
                "explanation": "æœªèƒ½è¯†åˆ«æ‚£è€…å§“å"
            }
            
        # è·å–è¯¥æ‚£è€…çš„å®é™…æ•°æ®ç»“æ„
        patient_data = get_patient_metadata(patient_name)
        if not patient_data:
            logger.warning(f"æœªæ‰¾åˆ°æ‚£è€… {patient_name} çš„æ•°æ®")
            return {
                "query_type": "åŸºæœ¬ä¿¡æ¯",
                "field": "all",
                "patient_name": patient_name,
                "explanation": f"æœªæ‰¾åˆ°æ‚£è€… {patient_name} çš„æ•°æ®"
            }
            
        prompt = f"""
        è¯·åˆ†æä»¥ä¸‹åŒ»ç–—æŸ¥è¯¢ï¼Œæå–æŸ¥è¯¢æ„å›¾å’Œå…³é”®ä¿¡æ¯ã€‚ç›´æ¥è¿”å›JSONå¯¹è±¡ï¼Œä¸è¦æ·»åŠ ä»»ä½•markdownæ ¼å¼æˆ–ä»£ç å—æ ‡è®°ã€‚

        æŸ¥è¯¢æ–‡æœ¬ï¼š{query_text}

        æ‚£è€… {patient_name} çš„å®é™…æ•°æ®ç»“æ„ä¸‹ï¼š
        {json.dumps(patient_data, ensure_ascii=False, indent=2)}

        ä½ éœ€è¦åˆ†æç”¨æˆ·çš„æŸ¥è¯¢æ„å›¾ï¼Œè¿”å›ä¸€ä¸ªJSONå¯¹è±¡ï¼ˆä¸è¦æ·»åŠ ä»»ä½•markdownæ ¼å¼æˆ–ä»£ç å—æ ‡è®°ï¼‰ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
        - query_type: æŸ¥è¯¢ç±»å‹ï¼Œå¿…ä»¥ä¸‹ä¹‹ä¸€ï¼šåŸºæœ¬ä¿¡æ¯/ä¸»è¯‰ä¸è¯Šæ–­/ç°ç—…å²/ç”Ÿå‘½ä½“å¾/ç”ŸåŒ–æŒ‡æ ‡/è¯Šç–—ç»è¿‡
        - field: å…·ä½“æŸ¥è¯¢çš„å­—æ®µåï¼Œå¦‚æœæ˜¯æŸ¥è¯¢æ•´ä¸ªç±»åˆ«ï¼Œè¯·è¿”å›"all"
        - patient_name: æ‚£è€…å§“å
        - explanation: æŸ¥è¯¢æ„å›¾çš„è§£é‡Š

        å¦‚æœæ˜¯æŸ¥è¯¢ä¸ªäººä¿¡æ¯ï¼Œåº”è¿”å›ï¼š
        {{
            "query_type": "åŸºæœ¬ä¿¡æ¯",
            "field": "all",
            "patient_name": "{patient_name}",
            "explanation": "æŸ¥è¯¢æ‚£è€…çš„æ‰€æœ‰åŸºæœ¬ä¿¡æ¯"
        }}

        å¦‚æœæ˜¯æŸ¥è¯¢ä¸ªç±»åˆ«çš„æ‰€æœ‰ä¿¡æ¯ï¼ˆå¦‚"ç”ŸåŒ–æŒ‡æ ‡"ã€"ä¸»è¯‰ä¸è¯Šæ–­"ç­‰ï¼‰ï¼Œè¯·å°†fieldè®¾ç½®ä¸º"all"ã€‚
        å¦‚æœæ˜¯æŸ¥è¯¢å…·ä½“çš„æŒ‡æ ‡æˆ–ç—‡çŠ¶ï¼ˆå¦‚"ç™½ç»†èƒ"ã€"è¡€å‹"ç­‰ï¼‰ï¼Œè¯·å°†fieldè®¾ç½®ä¸ºå…·ä½“çš„æŒ‡æ ‡åç§°ã€‚

        è¯·åˆ†æè¿™ä¸ªæŸ¥è¯¢å¹¶è¿”å›JSONï¼ˆä¸è¦æ·»åŠ markdownæ ¼å¼ï¼‰
        """

        client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_API_BASE")
        )
        
        response = client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—æŸ¥è¯¢åˆ†æåŠ©æ‰‹ã€‚è¯·ç›´æ¥è¿”å›JSONå¯¹è±¡ï¼Œä¸è¦æ·»åŠ ä»»ä½•markdownæ ¼å¼æˆ–ä»£ç å—æ ‡è®°ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            response_format={"type": "json_object"}
        )
        
        content = response.choices[0].message.content.strip()
        logger.info(f"OpenAI APIè¿”å›å†…å®¹: {content}")
        
        # å°è¯•è§£æè¿”å›å†…å®¹
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
            try:
                result = json.loads(content)
            except json.JSONDecodeError:
                logger.warning("ç›´æ¥è§£æJSONå¤±è´¥ï¼Œå°è¯•æ¸…ç†å†…å®¹åé‡æ–°è§£æ")
                # å¦‚æœå¤±è´¥ï¼Œå°è¯•æ¸…ç†å†…å®¹ï¼ˆå»é™¤å¯èƒ½çš„è½¬ä¹‰å­—ç¬¦ç­‰ï¼‰
                cleaned_content = content.replace('\n', '').replace('\r', '').strip()
                result = json.loads(cleaned_content)
            
            # å¦‚æœç»“æœè¢«åŒ…è£…åœ¨responseå­—æ®µä¸­ï¼Œæå–å†…å±‚JSON
            if isinstance(result, dict) and "response" in result:
                try:
                    inner_content = result["response"]
                    if isinstance(inner_content, str):
                        # æ¸…ç†å†…å±‚JSONå­—ç¬¦ä¸²
                        inner_content = inner_content.replace('\n', '').replace('\r', '').strip()
                        result = json.loads(inner_content)
                    elif isinstance(inner_content, dict):
                        result = inner_content
                except json.JSONDecodeError as e:
                    logger.error(f"è§£æresponseå­—æ®µå¤±è´¥: {str(e)}")
                    result = {
                        "query_type": "åŸºæœ¬ä¿¡æ¯",
                        "field": "all",
                        "patient_name": patient_name,
                        "explanation": "è§£ææŸ¥è¯¢æ„å›¾æ—¶å‡ºç°é”™è¯¯"
                    }
            
            # éªŒè¯ç»“æœæ ¼å¼
            if not isinstance(result, dict):
                raise ValueError("è¿”å›ç»“æœä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„JSONå¯¹è±¡")
            
            # éªŒè¯å¿…è¦å­—æ®µ
            required_fields = ["query_type", "field", "patient_name", "explanation"]
            missing_fields = [field for field in required_fields if field not in result]
            if missing_fields:
                logger.warning(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
                for field in missing_fields:
                    if field == "query_type":
                        result[field] = "åŸºæœ¬ä¿¡æ¯"
                    elif field == "field":
                        result[field] = "all"
                    elif field == "patient_name":
                        result[field] = patient_name
                    elif field == "explanation":
                        result[field] = "æŸ¥è¯¢æ‚£è€…ä¿¡æ¯"
            
            # éªŒè¯query_typeæ˜¯å¦ä¸ºæœ‰æ•ˆå€¼
            valid_query_types = ["åŸºæœ¬ä¿¡æ¯", "ä¸»è¯‰ä¸è¯Šæ–­", "ç°ç—…å²", "ç”Ÿå‘½ä½“å¾", "ç”ŸåŒ–æŒ‡æ ‡", "è¯Šç–—ç»è¿‡"]
            if result["query_type"] not in valid_query_types:
                logger.warning(f"æ— æ•ˆquery_type: {result['query_type']}, ä½¿ç”¨é»˜è®¤å€¼")
                result["query_type"] = "åŸºæœ¬ä¿¡æ¯"
            
            # ç¡®ä¿patient_nameä¸æŸ¥ä¸­è¯†åˆ«çš„ä¸€è‡´
            if result["patient_name"] != patient_name:
                logger.warning(f"patient_nameä¸åŒ¹é…: {result['patient_name']} != {patient_name}")
                result["patient_name"] = patient_name
            
            # å¤„ç†fieldå€¼
            if result["field"] == result["query_type"] or result["field"] in valid_query_types:
                logger.info(f"å°†fieldæ”¹ä¸º {result['field']}")
                result["field"] = "all"
            
            logger.info(f"æŸ¥è¯¢æ„å›¾åˆ†æç»“æœ: {json.dumps(result, ensure_ascii=False)}")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {str(e)}, åŸå§‹å†…å®¹: {content}")
            return {
                "query_type": "åŸºæœ¬ä¿¡æ¯",
                "field": "all",
                "patient_name": patient_name,
                "explanation": "è§£ææŸ¥è¯¢æ„å›¾æ—¶å‡ºç°é”™è¯¯"
            }
            
    except Exception as e:
        logger.error(f"åˆ†ææŸ¥è¯¢æ„å›¾å¤±è´¥: {str(e)}")
        return {
            "query_type": "åŸºæœ¬ä¿¡æ¯",
            "field": "all",
            "patient_name": patient_name if 'patient_name' in locals() else None,
            "explanation": "åˆ†ææŸ¥è¯¢æ„å›¾æ—¶å‡ºç°é”™è¯¯"
        }

def search_graph_data(query_text: str) -> List[Dict[str, Any]]:
    """åŸºäºå›¾æ•°æ®çš„æœç´¢"""
    try:
        # ä½¿ç”¨GPTåˆ†ææŸ¥è¯¢æ„å›¾
        analysis = analyze_graph_query(query_text)
        query_type = analysis.get("query_type")
        field = analysis.get("field")
        patient_name = analysis.get("patient_name")
        
        if not all([query_type, patient_name]):
            logger.error("æŸ¥è¯¢æ„å›¾åˆ†æç»“æœä¸å®Œæ•´")
            return []
        
        # ä½¿ç”¨å›¾æ•°æ®åº“æœç´¢
        with OracleGraphStore() as graph_store:
            # è·å–æ‚£è€…ä¿¡æ¯
            patient_info = graph_store.get_patient_info(patient_name)
            if not patient_info:
                return []
            
            # æ ¹æ®æŸ¥è¯¢ç±»å‹è¿”å›ç»“æœ
            if query_type == "åŸºæœ¬ä¿¡æ¯":
                if field == "all":
                    # è¿”å›æ‰€æœ‰ä¿¡æ¯
                    info = patient_info.get("æ‚£è€…", {}).get("åŸºæœ¬ä¿¡æ¯", {})
                    if not info:
                        info = patient_info.get("åŸºæœ¬ä¿¡æ¯", {})
                    if info:
                        result = []
                        for k, v in info.items():
                            result.append(f"{k}ï¼š{v}")
                        return [{"type": "answer", "data": {
                            "question": query_text,
                            "answer": f"{patient_name}çš„åŸºæœ¬ä¿¡æ¯ï¼š\n" + "\n".join(result),
                            "explanation": analysis.get("explanation")
                        }}]
                else:
                    # æŸ¥è¯¢ç‰¹å®šå­—æ®µ
                    value = None
                    # å…ˆå°è¯•ä»æ‚£è€….åŸºæœ¬ä¿¡æ¯ä¸­è·å–
                    info = patient_info.get("æ‚£è€…", {}).get("åŸºæœ¬ä¿¡æ¯", {})
                    if not info:
                        # å¦‚æœæ²¡æœ‰ï¼Œåˆ™ä»åŸºæœ¬ä¿¡æ¯ä¸­è·å–
                        info = patient_info.get("åŸºæœ¬ä¿¡æ¯", {})
                    value = info.get(field)
                    if value:
                        return [{"type": "answer", "data": {
                            "question": query_text,
                            "answer": f"{patient_name}çš„{field}æ˜¯{value}",
                            "explanation": analysis.get("explanation")
                        }}]
            
            elif query_type == "ä¸»è¯‰ä¸è¯Šæ–­":
                items = patient_info.get("ä¸»è¯‰ä¸è¯Šæ–­", [])
                if field == "all":
                    results = []
                    # åˆ†ç±»å¤„ç†ä¸»è¯‰å’Œè¯Šæ–­
                    chief_complaints = []
                    admission_diagnoses = []
                    discharge_diagnoses = []
                    for item in items:
                        if item.get("ç±»å‹") == "ä¸»è¯‰":
                            chief_complaints.append(item.get("å†…å®¹"))
                        elif item.get("ç±»å‹") == "å…¥é™¢è¯Šæ–­":
                            admission_diagnoses.append(item.get("å†…å®¹"))
                        elif item.get("ç±»å‹") == "å‡ºé™¢è¯Šæ–­":
                            discharge_diagnoses.append(item.get("å†…å®¹"))
                    
                    # ç»„ç»‡è¿”å›å†…å®¹
                    if chief_complaints:
                        results.append("ä¸»è¯‰ï¼š")
                        results.extend([f"- {complaint}" for complaint in chief_complaints])
                    if admission_diagnoses:
                        results.append("\nå…¥é™¢è¯Šæ–­ï¼š")
                        results.extend([f"- {diagnosis}" for diagnosis in admission_diagnoses])
                    if discharge_diagnoses:
                        results.append("\nå‡ºé™¢è¯Šæ–­ï¼š")
                        results.extend([f"- {diagnosis}" for diagnosis in discharge_diagnoses])
                        
                    if results:
                        return [{"type": "answer", "data": {
                            "question": query_text,
                            "answer": f"{patient_name}çš„ä¸»è¯‰ä¸è¯Šæ–­ï¼š\n" + "\n".join(results),
                            "explanation": analysis.get("explanation")
                        }}]
                else:
                    results = []
                    for item in items:
                        if field.lower() in item.get("ç±»å‹", "").lower():
                            results.append(item.get("å†…å®¹"))
                    if results:
                        return [{"type": "answer", "data": {
                            "question": query_text,
                            "answer": f"{patient_name}çš„{field}ï¼š\n" + "\n".join([f"- {r}" for r in results]),
                            "explanation": analysis.get("explanation")
                        }}]
            
            elif query_type == "ç°ç—…å²":
                items = patient_info.get("ç°ç—…å²", [])
                if field == "all":
                    results = []
                    for item in items:
                        symptom = item.get("ç—‡çŠ¶", "")
                        description = item.get("æè¿°", "")
                        if description:
                            results.append(f"- {symptom}ï¼š{description}")
                        else:
                            results.append(f"- {symptom}")
                    if results:
                        return [{"type": "answer", "data": {
                            "question": query_text,
                            "answer": f"{patient_name}çš„ç°ç—…å²ï¼š\n" + "\n".join(results),
                            "explanation": analysis.get("explanation")
                        }}]
                else:
                    results = []
                    for item in items:
                        if field.lower() in item.get("ç—‡çŠ¶", "").lower():
                            description = item.get("æè¿°", "")
                            if description:
                                results.append(f"{item.get('ç—‡çŠ¶')}ï¼š{description}")
                            else:
                                results.append(item.get('ç—‡çŠ¶'))
                    if results:
                        return [{"type": "answer", "data": {
                            "question": query_text,
                            "answer": f"{patient_name}çš„{field}ï¼š\n" + "\n".join(results),
                            "explanation": analysis.get("explanation")
                        }}]
            
            elif query_type == "ç”Ÿå‘½ä½“å¾":
                items = patient_info.get("ç”Ÿå‘½ä½“å¾", [])
                if field == "all":
                    results = []
                    for item in items:
                        results.append(f"- {item.get('æŒ‡æ ‡')}ï¼š{item.get('æ•°å€¼')}{item.get('å•ä½', '')}")
                    if results:
                        return [{"type": "answer", "data": {
                            "question": query_text,
                            "answer": f"{patient_name}çš„ç”Ÿå‘½ä½“å¾ï¼š\n" + "\n".join(results),
                            "explanation": analysis.get("explanation")
                        }}]
                else:
                    for item in items:
                        if field.lower() in item.get("æŒ‡æ ‡", "").lower():
                            return [{"type": "answer", "data": {
                                "question": query_text,
                                "answer": f"{patient_name}çš„{field}æ˜¯ï¼š{item.get('æ•°å€¼')}{item.get('å•ä½', '')}",
                                "explanation": analysis.get("explanation")
                            }}]
            
            elif query_type == "ç”ŸåŒ–æŒ‡æ ‡":
                items = patient_info.get("ç”ŸåŒ–æŒ‡æ ‡", [])
                if field == "all":
                    results = []
                    # æŒ‰ç…§å‚è€ƒèŒƒå›´åˆ†ç±»
                    abnormal_items = []
                    normal_items = []
                    for item in items:
                        result_str = f"- {item.get('é¡¹ç›®')}ï¼š{item.get('ç»“æœ')}{item.get('å•ä½', '')}"
                        if item.get('å‚è€ƒèŒƒå›´') == 'å¼‚å¸¸':
                            abnormal_items.append(result_str + " (å¼‚å¸¸)")
                        else:
                            normal_items.append(result_str + " (æ­£å¸¸)")
                    
                    # ç»„ç»‡è¿”å›å†…å®¹
                    if abnormal_items:
                        results.append("å¼‚å¸¸æŒ‡æ ‡ï¼š")
                        results.extend(abnormal_items)
                    if normal_items:
                        if results:  # å¦‚æœå·²ç»æœ‰å¼‚å¸¸æŒ‡æ ‡ï¼Œæ·»åŠ ç©ºè¡Œ
                            results.append("")
                        results.append("æ­£å¸¸æŒ‡æ ‡ï¼š")
                        results.extend(normal_items)
                        
                    if results:
                        return [{"type": "answer", "data": {
                            "question": query_text,
                            "answer": f"{patient_name}çš„ç”ŸåŒ–æŒ‡æ ‡ï¼š\n" + "\n".join(results),
                            "explanation": analysis.get("explanation")
                        }}]
                else:
                    for item in items:
                        if field.lower() in item.get("é¡¹ç›®", "").lower():
                            return [{"type": "answer", "data": {
                                "question": query_text,
                                "answer": f"{patient_name}çš„{field}æ˜¯ï¼š{item.get('ç»“æœ')}{item.get('å•ä½', '')} ({item.get('å‚è€ƒèŒƒå›´', '')})",
                                "explanation": analysis.get("explanation")
                            }}]
            
            elif query_type == "è¯Šç–—ç»è¿‡":
                items = patient_info.get("è¯Šç–—ç»è¿‡", [])
                if field == "all":
                    results = []
                    # åˆ†ç±»å¤„ç†è¯Šç–—ç»è¿‡å’Œå‡ºé™¢åŒ»å˜±
                    diagnoses = []
                    advices = []
                    for item in items:
                        if item.get("ç±»å‹") == "è¯Šç–—ç»è¿‡":
                            diagnoses.append(item.get("å†…å®¹"))
                        elif item.get("ç±»å‹") == "å‡ºé™¢åŒ»å˜±":
                            advices.append(item.get("å†…å®¹"))
                    
                    # ç»„ç»‡è¿”å›å†…å®¹
                    if diagnoses:
                        results.append("è¯Šç–—ç»è¿‡ï¼š")
                        results.extend([f"- {diagnosis}" for diagnosis in diagnoses])
                    if advices:
                        if results:  # å¦‚æœå·²ç»æœ‰è¯Šç–—ç»è¿‡ï¼Œæ·»åŠ ç©ºè¡Œ
                            results.append("")
                        results.append("å‡ºé™¢åŒ»å˜±ï¼š")
                        results.extend([f"- {advice}" for advice in advices])
                        
                    if results:
                        return [{"type": "answer", "data": {
                            "question": query_text,
                            "answer": f"{patient_name}çš„è¯Šç–—ç»è¿‡ï¼š\n" + "\n".join(results),
                            "explanation": analysis.get("explanation")
                        }}]
                else:
                    results = []
                    for item in items:
                        if field.lower() in item.get("ç±»å‹", "").lower():
                            results.append(item.get("å†…å®¹"))
                    if results:
                        return [{"type": "answer", "data": {
                            "question": query_text,
                            "answer": f"{patient_name}çš„{field}ï¼š\n" + "\n".join([f"- {r}" for r in results]),
                            "explanation": analysis.get("explanation")
                        }}]
            
            return []
            
    except Exception as e:
        logger.error(f"å›¾æ•°æ®æœç´¢å¤±è´¥: {str(e)}")
        return []

def display_graph_results(results: List[Dict[str, Any]], query_text: str):
    """æ˜¾ç¤ºå›¾æ•°æ®æœç´¢ç»“æœ"""
    if not results:
        st.warning("æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
        return
        
    for result in results:
        if result["type"] == "answer":
            data = result["data"]
            st.write(data["answer"])

def process_graph_data(file_path: str, content: str) -> bool:
    """å¤„ç†æ–‡æ¡£çš„å›¾æ•°æ®"""
    try:
        # åªå¤„ç†å›¾æ•°æ®
        graph_parser = MedicalGraphParser()
        graph_result = graph_parser.parse_to_graph(content, file_path)
        
        if "error" in graph_result:
            return False
            
        return True
    except Exception as e:
        logger.error(f"å¤„ç†å›¾æ•°æ®å¤±è´¥: {str(e)}")
        return False

def visualize_patient_graph(patient_info: Dict[str, Any]) -> str:
    """ä½¿ç”¨pyviså¯è§†åŒ–æ‚£è€…çš„å±æ€§å›¾"""
    try:
        # åˆ›å»ºç½‘ç»œå›¾
        net = Network(height="600px", width="100%", bgcolor="#ffffff", font_color="black", directed=False)
        
        # è®¾ç½®ç‰©ç†å¸ƒå±€é€‰é¡¹
        net.set_options("""
        {
          "nodes": {
            "font": {
              "size": 14,
              "face": "Microsoft YaHei"
            }
          },
          "edges": {
            "color": {
              "color": "#666666",
              "highlight": "#000000"
            }
          },
          "physics": {
            "enabled": true,
            "solver": "forceAtlas2Based",
            "forceAtlas2Based": {
              "gravitationalConstant": -50,
              "centralGravity": 0.01,
              "springLength": 100,
              "springConstant": 0.08,
              "damping": 0.4,
              "avoidOverlap": 0.5
            }
          }
        }
        """)
        
        # æ·»åŠ æ‚£è€…èŠ‚ç‚¹ï¼ˆä¸­å¿ƒèŠ‚ç‚¹ï¼‰
        patient_name = patient_info.get('å§“å', 'æœªçŸ¥æ‚£è€…')
        
        net.add_node(patient_name, 
                    label=patient_name,
                    color='#add8e6',  # lightblue
                    size=30,
                    shape='circle')
        
        # æ·»åŠ åŸºæœ¬ä¿¡æ¯èŠ‚ç‚¹
        basic_info = patient_info.get('åŸºæœ¬ä¿¡æ¯', {})
        if basic_info:
            for key, value in basic_info.items():
                node_id = f'basic_{key}'
                net.add_node(node_id,
                            label=f'{key}ï¼š{value}',
                            color='#90EE90',  # lightgreen
                            size=20,
                            shape='box')
                net.add_edge(patient_name, node_id, title='åŸºæœ¬ä¿¡æ¯')
        
        # æ·»åŠ ä¸»è¯‰ä¸è¯Šæ–­èŠ‚ç‚¹
        if 'ä¸»è¯‰ä¸è¯Šæ–­' in patient_info:
            for i, item in enumerate(patient_info['ä¸»è¯‰ä¸è¯Šæ–­']):
                node_id = f'diag_{i}'
                net.add_node(node_id,
                            label=f"{item.get('ç±»å‹')}ï¼š{item.get('å†…å®¹')}",
                            color='#FFB6C1',  # lightpink
                            size=20,
                            shape='box')
                net.add_edge(patient_name, node_id, title='ä¸»è¯‰ä¸è¯Šæ–­')
        
        # æ·»åŠ ç°ç—…å²èŠ‚ç‚¹
        if 'ç°ç—…å²' in patient_info:
            for i, item in enumerate(patient_info['ç°ç—…å²']):
                node_id = f'hist_{i}'
                net.add_node(node_id,
                            label=f"{item.get('ç—‡çŠ¶')}ï¼š{item.get('æè¿°')}",
                            color='#FFFFE0',  # lightyellow
                            size=20,
                            shape='box')
                net.add_edge(patient_name, node_id, title='ç°ç—…å²')

        # æ·»åŠ ç”Ÿå‘½ä½“å¾èŠ‚ç‚¹
        if 'ç”Ÿå‘½ä½“å¾' in patient_info:
            for i, item in enumerate(patient_info['ç”Ÿå‘½ä½“å¾']):
                node_id = f'vital_{i}'
                net.add_node(node_id,
                            label=f"{item.get('æŒ‡æ ‡')}ï¼š{item.get('æ•°å€¼')}",
                            color='#F08080',  # lightcoral
                            size=20,
                            shape='box')
                net.add_edge(patient_name, node_id, title='ç”Ÿå‘½ä½“å¾')
        
        # æ·»åŠ ç”ŸåŒ–æŒ‡æ ‡ç‚¹
        if 'ç”ŸåŒ–æ ‡' in patient_info:
            for i, item in enumerate(patient_info['ç”ŸåŒ–æŒ‡æ ‡']):
                node_id = f'biochem_{i}'
                net.add_node(node_id,
                            label=f"{item.get('é¡¹ç›®')}ï¼š{item.get('ç»“æœ')}",
                            color='#DDA0DD',  # plum
                            size=20,
                            shape='box')
                net.add_edge(patient_name, node_id, title='ç”ŸåŒ–æŒ‡æ ‡')
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜HTML
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.html', encoding='utf-8') as f:
            try:
                net.save_graph(f.name)
                return f.name
            except Exception as e:
                raise
                
    except Exception as e:
        raise

def display_parsed_documents():
    """æ˜¾ç¤ºå·²è§£æçš„æ–‡æ¡£"""
    st.subheader("æŸ¥çœ‹å·²è§£æçš„æ–‡æ¡£")
    
    try:
        with OracleGraphStore() as graph_store:
            patients = graph_store.get_all_patients()
            
            if not patients:
                st.info("ğŸ“­ æ•°æ®åº“ä¸­æš‚æ— ç»“æ„åŒ–æ–‡æ¡£ï¼Œè¯·å…ˆåœ¨æ–‡æ¡£ç®¡ç†ä¸­ä¸Šä¼ å¹¶ç»“æ„åŒ–æ–‡æ¡£")
                return
                
            st.write("å·²è§£æçš„æ–‡æ¡£ä¸­åŒ…å«ä»¥ä¸‹æ‚£è€…ï¼š")
            
            # æ‚£åˆ—è¡¨
            for patient in patients:
                patient_name = patient.get('å§“å', 'æœªçŸ¥æ‚£è€…')
                # ä½¿ç”¨expanderä½¿æ¯ä¸ªæ‚£è€…çš„ä¿¡æ¯é»˜è®¤æŠ˜å 
                with st.expander(f"ğŸ“‹ {patient_name}", expanded=False):
                    # è·å–æ‚£è€…å®Œæ•´ä¿¡æ¯
                    patient_info = graph_store.get_patient_info(patient_name)
                    if patient_info:
                        # åˆ›å»ºä¸¤é¡µæ ‡ç­¾
                        tab1, tab2 = st.tabs(["çŸ¥è¯†å›¾è°±", "å®Œæ•´æ•°æ®"])
                        
                        with tab1:
                            try:
                                # åˆ›å»ºå¹¶æ˜¾ç¤ºäº¤äº’å¼ç½‘ç»œå›¾
                                html_path = visualize_patient_graph(patient_info)
                                with open(html_path, 'r', encoding='utf-8') as f:
                                    html_content = f.read()
                                components.html(html_content, height=600)
                                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                                os.unlink(html_path)
                            except Exception as e:
                                st.error(f"æ˜¾ç¤ºå›¾å½¢æ—¶å‡ºé”™: {str(e)}")
                        
                        with tab2:
                            st.json(patient_info)
                    else:
                        st.error("æ— è·å–æ‚£è€…è¯¦ç»†ä¿¡æ¯")
            
    except Exception as e:
        logger.error(f"æ˜¾ç¤ºå·²è§£ææ–‡æ¡£å¤±è´¥: {str(e)}")
        st.error("æ˜¾ç¤ºå·²è§£ææ–‡æ¡£æ—¶å‡ºç°é”™è¯¯")

def display_document_management():
    """æ˜¾ç¤ºæ–‡æ¡£ç®¡ç†ç•Œé¢"""
    st.header("æ–‡æ¡£ç®¡ç†")
    
    try:
        # æ˜¾ç¤ºå·²ä¸Šä¼ çš„æ–‡æ¡£
        st.subheader("å·²ä¸Šä¼ çš„æ–‡æ¡£")
        files = list(UPLOAD_DIR.glob("*.*"))
        
        if files:
            # åˆ›å»ºæ–‡æ¡£åˆ—è¡¨
            for file in files:
                try:
                    col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
                    
                    with col1:
                        st.write(file.name)
                        
                    with col2:
                        if st.button("å‘é‡åŒ–", key=f"vec_{file.name}"):
                            with st.spinner("æ­£åœ¨å‘é‡åŒ–..."):
                                try:
                                    if vectorize_document(file):
                                        st.success("å‘é‡åŒ–æˆåŠŸ")
                                    else:
                                        st.error("å‘é‡åŒ–å¤±è´¥")
                                except Exception as e:
                                    logger.error(f"å‘é‡åŒ–æ–‡æ¡£å¤±è´¥: {str(e)}")
                                    st.error(f"å‘é‡åŒ–å¤±è´¥: {str(e)}")
                                    
                    with col3:
                        if st.button("ç»“æ„åŒ–", key=f"struct_{file.name}"):
                            with st.spinner("æ­£åœ¨ç»“æ„åŒ–..."):
                                try:
                                    # åˆ›å»ºæ–‡ä»¶å¯¹è±¡
                                    file_obj = FileObject(file)
                                    try:
                                        result = parse_document_to_json(file_obj)
                                        if result:
                                            if "error" in result:
                                                st.error(result["error"])
                                            else:
                                                st.success("ç»“æ„åŒ–æˆåŠŸ")
                                        else:
                                            st.error("ç»“æ„åŒ–å¤±è´¥")
                                    finally:
                                        file_obj.close()
                                except Exception as e:
                                    logger.error(f"ç»“æ„åŒ–æ–‡æ¡£å¤±è´¥: {str(e)}")
                                    st.error(f"ç»“æ„åŒ–å¤±è´¥: {str(e)}")
                                    
                    with col4:
                        if st.button("å›¾æ•°æ®", key=f"graph_{file.name}"):
                            with st.spinner("æ­£åœ¨å¤„ç†å›¾æ•°æ®..."):
                                try:
                                    # è¯»å–æ–‡ä»¶å†…å®¹
                                    content = read_file_content(file)
                                    if content:
                                        if process_graph_data(file.name, content):
                                            st.success("å›¾æ•°æ®å¤„ç†æˆåŠŸ")
                                        else:
                                            st.error("å›¾æ•°æ®å¤„ç†å¤±è´¥")
                                    else:
                                        st.error("æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹")
                                except Exception as e:
                                    logger.error(f"å¤„ç†å›¾æ•°æ®å¤±è´¥: {str(e)}")
                                    st.error(f"å¤„ç†å›¾æ•°æ®å¤±è´¥: {str(e)}")
                                    
                    st.markdown("---")
                    
                except Exception as e:
                    logger.error(f"å¤„ç†æ–‡æ¡£ {file.name} æ—¶å‡ºé”™: {str(e)}")
                    continue
                    
        else:
            st.info("æš‚æ— ä¸Šä¼ çš„æ–‡æ¡£")
            
        # æ–‡ä»¶ä¸Šä¼ éƒ¨åˆ†
        uploaded_file = st.file_uploader("ä¸Šä¼ åŒ»ç–—æ–‡æ¡£", type=["pdf", "docx", "txt"])
        
        if uploaded_file:
            col1, col2 = st.columns([2, 1])
            with col1:
                st.write(f"å·²é€‰æ‹© {uploaded_file.name}")
            with col2:
                if st.button("ä¿å­˜æ–‡æ¡£"):
                    with st.spinner(f"æ­£åœ¨ä¿å­˜ {uploaded_file.name}..."):
                        try:
                            file_path = save_uploaded_file(uploaded_file)
                            if file_path:
                                st.success(f"æ–‡ä»¶ä¿å­˜æˆåŠŸ: {file_path}")
                            else:
                                st.error("æ–‡ä»¶ä¿å­˜å¤±è´¥")
                        except Exception as e:
                            logger.error(f"ä¿å­˜ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {str(e)}")
                            st.error(f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}")
                            
    except Exception as e:
        logger.error(f"æ˜¾ç¤ºæ–‡æ¡£ç®¡ç†ç•Œé¢å¤±è´¥: {str(e)}")
        st.error(f"æ˜¾ç¤ºæ–‡æ¡£ç®¡ç†ç•Œé¢æ—¶å‡ºç°é”™è¯¯: {str(e)}")

def display_vector_search():
    """æ˜¾ç¤ºå‘é‡æ£€ç´¢ç•Œé¢"""
    st.header("å‘é‡æ£€ç´¢")
    
    # æ˜¾ç¤ºå·²å‘é‡åŒ–çš„æ–‡æ¡£åˆ—è¡¨
    with st.expander("æŸ¥çœ‹å·²å‘é‡åŒ–çš„æ–‡æ¡£", expanded=True):
        with OracleVectorStore() as vector_store:
            documents = vector_store.list_documents()
            if documents:
                st.write("å·²å‘é‡åŒ–çš„æ–‡æ¡£ï¼š")
                for doc in documents:
                    st.write(f"- {doc['file_path']} (å‘é‡æ•°: {doc['chunk_count']})")
            else:
                st.info("æš‚æ— å‘é‡åŒ–æ–‡æ¡£")
    
    # æœç´¢åŠŸèƒ½
    query = st.text_input("è¯·è¾“å…¥æœç´¢å†…å®¹")
    if query:
        with st.spinner("æ­£åœ¨æœç´¢å¹¶åˆ†æ..."):
            results = search_similar_documents(query, top_k=3)
            
            if results:
                # æ˜¾ç¤ºæœ€ç›¸å…³æ–‡æ¡£çš„ GPT åˆ†æç»“æœ
                st.subheader("GPT åˆ†æç»“æœ")
                st.write(results[0]['gpt_analysis'])
                
                # æ˜¾ç¤ºæ‰€æœ‰ç›¸å…³æ–‡æ¡£
                st.subheader("ç›¸å…³æ–‡æ¡£")
                for i, result in enumerate(results, 1):
                    similarity = 1 - result['similarity']
                    with st.expander(f"æ–‡æ¡£ {i}: {result['file_path']} (ç›¸ä¼¼åº¦: {similarity:.2%})"):
                        st.write(result['content'])
            else:
                st.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")

def display_structured_search():
    """æ˜¾ç¤ºç»“æ„åŒ–æ£€ç´¢ç•Œé¢"""
    st.header("ç»“æ„åŒ–æ£€ç´¢")
    
    try:
        # æ£€æŸ¥æ•°æ®åº“ä¸­çš„ç»“æ„åŒ–æ–‡æ¡£
        with OracleJsonStore() as json_store:
            # é¦–å…ˆæ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            check_table_sql = """
            SELECT table_name 
            FROM user_tables 
            WHERE table_name = 'DOCUMENT_JSON'
            """
            result = json_store.execute_search(check_table_sql)
            if not result:
                st.warning("æ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆåœ¨æ–‡æ¡£ç®¡ç†ä¸­ä¸Šä¼ å¹¶ç»“æ„åŒ–æ–‡æ¡£")
                return
            
            # è·å–æ‰€æœ‰æ–‡æ¡£
            check_sql = """
            SELECT doc_info, doc_json
            FROM DOCUMENT_JSON 
            ORDER BY id DESC
            """
            all_docs = json_store.execute_search(check_sql)
            if not all_docs:
                st.info("ğŸ“­ æ•°æ®åº“æš‚æ— ç»“æ„åŒ–æ–‡æ¡£ï¼Œè¯·å…ˆåœ¨æ–‡æ¡£ç®¡ç†ä¸­ä¸Šä¼ å¹¶ç»“æ„åŒ–æ–‡æ¡£")
                return
            
            # æ˜¾ç¤ºæ•°æ®åº“ä¸­çš„æ‰€æœ‰æ–‡æ¡£è¯¦ç»†ä¿¡æ¯
            st.subheader("ğŸ“š æ•°æ®åº“ä¸­æ‰€æœ‰æ–‡æ¡£")
            st.write(f"ğŸ“Š æ•°æ®åº“ä¸­å…±æœ‰ {len(all_docs)} ä¸ªæ–‡æ¡£")
            
            # å¤„ç†æ¯ä¸ªæ–‡æ¡£
            for doc in all_docs:
                try:
                    if not isinstance(doc.get('doc_json'), dict):
                        logger.warning(f"è·³è¿‡æ— æ•ˆçš„æ–‡æ¡£æ ¼å¼: {doc.get('doc_info', 'æœªçŸ¥')}")
                        continue
                        
                    data = doc['doc_json']
                    patient_name = data.get("æ‚£è€…å§“å", Path(doc['doc_info']).stem)
                    
                    # ä½¿ç”¨expanderä¸ºæ¯ä¸ªæ‚£è€…åˆ›å»ºæŠ˜å é¢æ¿
                    with st.expander(f"ğŸ“‹ {patient_name}", expanded=False):
                        # åˆ›å»ºæ ‡ç­¾é¡µ
                        tabs = st.tabs([
                            "åŸºæœ¬ä¿¡æ¯", "ä¸»è¯‰ä¸è¯Šæ–­", "ç°ç—…å²", 
                            "ç”Ÿå‘½ä½“å¾", "ç”ŸåŒ–æŒ‡æ ‡", "è¯Šç–—ç»è¿‡"
                        ])
                        
                        with tabs[0]:
                            if "åŸºæœ¬ä¿¡æ¯" in data:
                                st.json(data["åŸºæœ¬ä¿¡æ¯"])
                            else:
                                st.info("æœªè®°å½•åŸºæœ¬ä¿¡æ¯")
                        
                        with tabs[1]:
                            st.markdown("**ä¸»è¯‰**")
                            st.write(data.get("ä¸»è¯‰", "æœªè®°å½•"))
                            col1, col2 = st.columns(2)
                            with col1:
                                st.markdown("**å…¥é™¢è¯Šæ–­**")
                                for diag in data.get("å…¥é™¢è¯Šæ–­", []):
                                    st.write(f"- {diag}")
                            with col2:
                                st.markdown("**å‡ºé™¢è¯Šæ–­**")
                                for diag in data.get("å‡ºé™¢è¯Šæ–­", []):
                                    st.write(f"- {diag}")
                        
                        with tabs[2]:
                            st.markdown("**ç°ç—…å²**")
                            for item in data.get("ç°ç—…å²", []):
                                st.write(f"- {item}")
                        
                        with tabs[3]:
                            if "ç”Ÿå‘½ä½“å¾" in data:
                                st.json(data["ç”Ÿå‘½ä½“å¾"])
                            else:
                                st.info("æœªè®°å½•ç”Ÿå‘½ä½“å¾")
                        
                        with tabs[4]:
                            if "ç”ŸåŒ–æŒ‡æ ‡" in data:
                                st.json(data["ç”ŸåŒ–æŒ‡æ ‡"])
                            else:
                                st.info("æœªè®°å½•ç”ŸåŒ–æŒ‡æ ‡")
                        
                        with tabs[5]:
                            st.markdown("**è¯Šç–—ç»è¿‡**")
                            st.write(data.get("è¯Šç–—ç»è¿‡", "æœªè®°å½•"))
                            if "å‡ºé™¢åŒ»å˜±" in data:
                                st.markdown("**å‡ºé™¢åŒ»å˜±**")
                                for advice in data["å‡ºé™¢åŒ»å˜±"]:
                                    st.write(f"- {advice}")
                except Exception as e:
                    logger.error(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}, æ–‡æ¡£ä¿¡æ¯: {doc.get('doc_info', 'æœªçŸ¥')}")
                    continue
            
            # æœç´¢åŠŸèƒ½
            st.divider()
            st.subheader("ğŸ” æ™ºèƒ½æœç´¢")
            query = st.text_input("è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹ï¼ˆæ”¯æŒç»“æ„åŒ–æ•°æ®æœç´¢ï¼‰")
            
            if query:
                with st.spinner("æ­£åœ¨åˆ†ææŸ¥è¯¢å¹¶æœç´¢..."):
                    try:
                        results = search_documents(query)
                        if results:
                            # æ˜¾ç¤ºæœç´¢ç»“æœ
                            display_search_results(query, results)
                        else:
                            st.warning("æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
                    except Exception as e:
                        logger.error(f"æ‰§è¡Œæœç´¢æ—¶å‡ºé”™: {str(e)}")
                        st.error("æ‰§è¡Œæœç´¢æ—¶å‡ºç°é”™è¯¯")
                        
    except Exception as e:
        logger.error(f"æ£€ç´¢æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        st.error(f"æ£€ç´¢æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

def display_property_graph_search():
    """æ˜¾ç¤ºå±æ€§å›¾æ£€ç´¢ç•Œé¢"""
    st.header("å±æ€§å›¾æ£€ç´¢")
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs(["æŸ¥è¯¢æ¨¡æ¿", "è‡ªå®šä¹‰æŸ¥è¯¢"])
    
    with tab1:
        st.subheader("å¸¸ç”¨æŸ¥è¯¢æ¨¡æ¿")
        query_type = st.selectbox(
            "é€‰æ‹©æŸ¥è¯¢ç±»å‹",
            [
                "æ‚£è€…ç›¸ä¼¼ç—‡çŠ¶åˆ†æ",
                "æ‚£è€…ç”ŸåŒ–æŒ‡æ ‡å¼‚å¸¸å…³è”",
                "æ‚£è€…è¯Šæ–­å…³ç³»ç½‘ç»œ",
                "æ‚£è€…ç”¨è¯å…³è”åˆ†æ",
                "æ‚£è€…æ²»ç–—æ–¹æ¡ˆå¯¹æ¯”"
            ]
        )
        
        if query_type == "æ‚£è€…ç›¸ä¼¼ç—‡çŠ¶åˆ†æ":
            patient_name = st.selectbox("é€‰æ‹©æ‚£è€…", ["é©¬æŸæŸ", "å‘¨æŸæŸ", "åˆ˜æŸæŸ", "è’²æŸæŸ", "æ¨æŸæŸ"])
            if st.button("åˆ†æ"):
                with st.spinner("æ­£åœ¨åˆ†æç›¸ä¼¼ç—‡çŠ¶..."):
                    try:
                        with OracleGraphStore() as graph_store:
                            # ä¸»æŸ¥è¯¢
                            query = """
                            SELECT *
                            FROM GRAPH_TABLE ( MEDICAL_KG
                                MATCH (v1) -[e1]-> (s1), (v2) -[e2]-> (s2)
                                WHERE v1.ENTITY_TYPE = 'æ‚£è€…'
                                AND v2.ENTITY_TYPE = 'æ‚£è€…'
                                AND v1.ENTITY_NAME = :patient_name
                                AND v1.ENTITY_NAME != v2.ENTITY_NAME
                                AND e1.RELATION_TYPE = 'ç°ç—…å²'
                                AND e2.RELATION_TYPE = 'ç°ç—…å²'
                                COLUMNS (
                                    v1.ENTITY_NAME AS patient1,
                                    v2.ENTITY_NAME AS patient2,
                                    JSON_VALUE(s1.ENTITY_VALUE, '$.ç—‡çŠ¶') AS symptom1,
                                    JSON_VALUE(s2.ENTITY_VALUE, '$.ç—‡çŠ¶') AS symptom2
                                )
                            )
                            """
                            results = graph_store.execute_pgql(query, {"patient_name": patient_name})
                            if results:
                                # æ„å»ºç”¨äºåˆ†æçš„æ–‡æœ¬
                                analysis_text = []
                                target_symptoms = []
                                other_patients = {}
                                
                                # æ•´ç†ç—‡çŠ¶æ•°æ®
                                for result in results:
                                    if result['symptom1']:
                                        target_symptoms.append(result['symptom1'])
                                    if result['patient2'] not in other_patients:
                                        other_patients[result['patient2']] = set()
                                    if result['symptom2']:
                                        other_patients[result['patient2']].add(result['symptom2'])
                                
                                if target_symptoms:
                                    analysis_text.append(f"ç›®æ ‡æ‚£è€… {patient_name} çš„ç—‡çŠ¶ï¼š")
                                    for symptom in sorted(set(target_symptoms)):
                                        analysis_text.append(f"- {symptom}")
                                    
                                    analysis_text.append("\nå…¶ä»–æ‚£è€…çš„ç—‡çŠ¶ï¼š")
                                    for p_name, symptoms in other_patients.items():
                                        if symptoms:
                                            analysis_text.append(f"\n{p_name} çš„ç—‡çŠ¶ï¼š")
                                            for symptom in sorted(symptoms):
                                                analysis_text.append(f"- {symptom}")
                                    
                                    # è°ƒç”¨OpenAIè¿›è¡Œåˆ†æ
                                    with st.spinner("æ­£åœ¨åˆ†æç—‡çŠ¶ç›¸ä¼¼åº¦..."):
                                        try:
                                            client = OpenAI(
                                                api_key=os.getenv('OPENAI_API_KEY'),
                                                base_url=os.getenv('OPENAI_API_BASE')
                                            )
                                            
                                            # æ„å»ºæç¤ºè¯
                                            prompt = f"""è¯·åˆ†æä»¥ä¸‹æ‚£è€…çš„ç—‡çŠ¶ä¿¡æ¯ï¼Œæ‰¾å‡ºç—‡çŠ¶ä¹‹é—´çš„ç›¸ä¼¼æ€§å’Œå¯èƒ½çš„å…³è”ï¼š

æ‚£è€…ç—‡çŠ¶ä¿¡æ¯ï¼š
{chr(10).join(analysis_text)}

è¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¿›è¡Œåˆ†æï¼š
1. å„ä¸ªæ‚£è€…ä¸ç›®æ ‡æ‚£è€…ï¼ˆ{patient_name}ï¼‰ç—‡çŠ¶çš„ç›¸ä¼¼åº¦ï¼ˆç”¨ç™¾åˆ†æ¯”è¡¨ç¤ºï¼‰
2. ç—‡çŠ¶çš„ç›¸ä¼¼æ€§å’Œå…³è”æ€§åˆ†æ
3. å¯èƒ½çš„å…±åŒç—…å› 
4. éœ€è¦æ³¨æ„çš„åŒ»å­¦é—®é¢˜

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå¹¶å°½å¯èƒ½ä¸“ä¸šå’Œè¯¦ç»†ã€‚å¯¹äºç—‡çŠ¶ç›¸ä¼¼åº¦çš„åˆ†æï¼Œè¯·ç»™å‡ºå…·ä½“çš„ç™¾åˆ†æ¯”æ•°å€¼ã€‚"""

                                            response = client.chat.completions.create(
                                                model=os.getenv('OPENAI_MODEL', 'gpt-3.5-turbo'),
                                                messages=[
                                                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»å­¦é¡¾é—®ï¼Œæ“…é•¿åˆ†ææ‚£è€…ç—‡çŠ¶çš„ç›¸ä¼¼åº¦ã€‚è¯·ä»åŒ»å­¦ä¸“ä¸šçš„è§’åº¦åˆ†æç—‡çŠ¶çš„ç›¸å…³æ€§å’Œå¯èƒ½çš„ç—…å› ã€‚"},
                                                    {"role": "user", "content": prompt}
                                                ],
                                                temperature=0.7
                                            )
                                            
                                            analysis_result = response.choices[0].message.content
                                            st.write("### ç—‡çŠ¶åˆ†æç»“æœ")
                                            st.write(analysis_result)
                                        except Exception as e:
                                            st.error(f"åˆ†æå¤±è´¥: {str(e)}")
                                            logger.error(f"åˆ†æå¤±è´¥: {str(e)}", exc_info=True)
                                else:
                                    st.warning(f"æœªæ‰¾åˆ° {patient_name} çš„ç—‡çŠ¶è®°å½•")
                            else:
                                st.info("æœªæ‰¾åˆ°ä»»ä½•ç—‡çŠ¶è®°å½•")
                    except Exception as e:
                        st.error(f"åˆ†æå¤±è´¥: {str(e)}")
                        logger.error(f"åˆ†æå¤±è´¥: {str(e)}", exc_info=True)
                        
        elif query_type == "æ‚£è€…ç”ŸåŒ–æŒ‡æ ‡å¼‚å¸¸å…³è”":
            patient_name = st.selectbox("é€‰æ‹©æ‚£è€…", ["é©¬æŸæŸ", "å‘¨æŸæŸ", "åˆ˜æŸæŸ", "è’²æŸæŸ", "æ¨æŸæŸ"])
            if st.button("åˆ†æ"):
                with st.spinner("æ­£åœ¨åˆ†æç”ŸåŒ–æŒ‡æ ‡å¼‚å¸¸å…³è”..."):
                    try:
                        with OracleGraphStore() as graph_store:
                            # ä½¿ç”¨JSON_TABLEæŸ¥è¯¢å¼‚å¸¸ç”ŸåŒ–æŒ‡æ ‡
                            query = """
                            SELECT v.ENTITY_NAME as patient,
                                   i.é¡¹ç›® as indicator,
                                   i.ç»“æœ as value,
                                   i.å•ä½ as unit,
                                   i.å‚è€ƒèŒƒå›´ as reference
                            FROM MEDICAL_ENTITIES v,
                                 JSON_TABLE(v.ENTITY_VALUE, '$.ç”ŸåŒ–æŒ‡æ ‡[*]'
                                     COLUMNS (
                                         é¡¹ç›® VARCHAR2(100) PATH '$.é¡¹ç›®',
                                         ç»“æœ VARCHAR2(100) PATH '$.ç»“æœ',
                                         å•ä½ VARCHAR2(100) PATH '$.å•ä½',
                                         å‚è€ƒèŒƒå›´ VARCHAR2(100) PATH '$.å‚è€ƒèŒƒå›´'
                                     )
                                 ) i
                            WHERE v.ENTITY_TYPE = 'æ‚£è€…'
                            AND v.ENTITY_NAME = :patient_name
                            AND i.å‚è€ƒèŒƒå›´ = 'å¼‚å¸¸'
                            """
                            results = graph_store.execute_sql(query, {"patient_name": patient_name})
                            if results:
                                # æ„å»ºç”¨äºåˆ†æçš„æ–‡æœ¬
                                analysis_text = []
                                analysis_text.append(f"æ‚£è€… {patient_name} çš„å¼‚å¸¸ç”ŸåŒ–æŒ‡æ ‡ï¼š")
                                for result in results:
                                    analysis_text.append(f"- {result['indicator']}: {result['value']} {result['unit']}")
                                
                                # æ„å»ºæç¤ºè¯
                                prompt = f"""
                                è¯·åˆ†æä»¥ä¸‹æ‚£è€…çš„å¼‚å¸¸åŒ–æŒ‡ï¼Œç»™å‡ºä¸“ä¸šçš„åŒ»å­¦åˆ†ææ„è§ã€‚
                                è¯·åŒ…å«ä»¥ä¸‹æ–¹é¢ï¼š
                                1. å¼‚å¸¸æŒ‡æ ‡çš„ä¸´åºŠæ„ä¹‰
                                2. å¯èƒ½çš„ç—…ç†ç”Ÿç†æœºåˆ¶
                                3. éœ€è¦å…³æ³¨çš„å¥åº·é£é™©
                                4. å»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥çš„é¡¹ç›®
                                5. ç”Ÿæ´»æ–¹å¼å»ºè®®

                                {chr(10).join(analysis_text)}

                                è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€å›ç­”ã€‚
                                """

                                try:
                                    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
                                    client = OpenAI(
                                        api_key=os.getenv("OPENAI_API_KEY"),
                                        base_url=os.getenv("OPENAI_API_BASE")
                                    )
                                    
                                    # è°ƒç”¨OpenAI APIè¿›è¡Œåˆ†æ
                                    response = client.chat.completions.create(
                                        model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
                                        messages=[
                                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ä¸´åºŠåŒ»ç”Ÿï¼Œæ“…é•¿è§£è¯»å„ç§ç”ŸåŒ–æŒ‡æ ‡ã€‚"},
                                            {"role": "user", "content": prompt}
                                        ],
                                        temperature=0.7
                                    )
                                    
                                    # æ˜¾ç¤ºåˆ†æç»“æœ
                                    analysis = response.choices[0].message.content
                                    st.success(f"æ‰¾åˆ° {len(results)} ä¸ªå¼‚å¸¸æŒ‡æ ‡")
                                    st.markdown(analysis)
                                except Exception as e:
                                    st.error(f"åˆ†æå¤±è´¥: {str(e)}")
                            else:
                                st.info("æœªæ‰¾åˆ°å¼‚å¸¸ç”ŸåŒ–æŒ‡æ ‡è®°å½•")
                    except Exception as e:
                        st.error(f"åˆ†æå¤±è´¥: {str(e)}")
                        
        elif query_type == "æ‚£è€…è¯Šæ–­å…³ç³»ç½‘ç»œ":
            if st.button("åˆ†æ"):
                with st.spinner("æ­£åœ¨åˆ†æè¯Šæ–­å…³ç³»ç½‘ç»œ..."):
                    try:
                        with OracleGraphStore() as graph_store:
                            # ä½¿ç”¨JSON_TABLEä»å®ä½“è¡¨ä¸­æå–è¯Šæ–­ä¿¡æ¯
                            query = """
                            WITH DIAGNOSES AS (
                                SELECT 
                                    e.ENTITY_NAME as patient_name,
                                    d.ç±»å‹ as diagnosis_type,
                                    d.å†…å®¹ as diagnosis
                                FROM MEDICAL_ENTITIES e,
                                     JSON_TABLE(e.ENTITY_VALUE, '$.ä¸»è¯‰ä¸è¯Šæ–­[*]'
                                         COLUMNS (
                                             ç±»å‹ VARCHAR2(100) PATH '$.ç±»å‹',
                                             å†…å®¹ VARCHAR2(1000) PATH '$.å†…å®¹'
                                         )
                                     ) d
                                WHERE e.ENTITY_TYPE = 'æ‚£è€…'
                                AND d.ç±»å‹ IN ('å…¥é™¢è¯Šæ–­', 'å‡ºé™¢è¯Šæ–­')
                            )
                            SELECT DISTINCT 
                                d1.patient_name AS patient1,
                                d2.patient_name AS patient2,
                                d1.diagnosis_type AS diagnosis_type,
                                d1.diagnosis AS diagnosis_value
                            FROM DIAGNOSES d1
                            JOIN DIAGNOSES d2 ON d1.diagnosis = d2.diagnosis 
                                AND d1.diagnosis_type = d2.diagnosis_type
                                AND d1.patient_name < d2.patient_name
                            ORDER BY d1.patient_name, d2.patient_name, d1.diagnosis_type
                            """
                            logger.info("æ‰§è¡ŒSQLæŸ¥è¯¢: %s", query)
                            results = graph_store.execute_sql(query)
                            logger.info("æŸ¥è¯¢ç»“æœ: %r", results)
                            
                            if results:
                                # åˆ›å»ºç½‘ç»œå›¾
                                net = Network(height="600px", width="100%", bgcolor="#ffffff", font_color="black")
                                
                                # è®¾ç½®ç‰©ç†å¸ƒå±€é€‰é¡¹
                                net.set_options("""
                                {
                                    "nodes": {
                                        "font": {
                                            "size": 16,
                                            "face": "Microsoft YaHei"
                                        }
                                    },
                                    "edges": {
                                        "color": {
                                            "color": "#666666",
                                            "highlight": "#000000"
                                        },
                                        "font": {
                                            "size": 12,
                                            "face": "Microsoft YaHei"
                                        }
                                    },
                                    "physics": {
                                        "enabled": true,
                                        "solver": "forceAtlas2Based",
                                        "forceAtlas2Based": {
                                            "gravitationalConstant": -50,
                                            "centralGravity": 0.01,
                                            "springLength": 200,
                                            "springConstant": 0.08,
                                            "damping": 0.4,
                                            "avoidOverlap": 0.5
                                        }
                                    }
                                }
                                """)
                                
                                # æ·»åŠ èŠ‚ç‚¹å’Œè¾¹
                                nodes = set()
                                diagnosis_data = []
                                
                                for result in results:
                                    patient1 = result['patient1']
                                    patient2 = result['patient2']
                                    diagnosis_type = result['diagnosis_type']
                                    diagnosis_value = result['diagnosis_value']
                                    
                                    # æ”¶é›†è¯Šæ–­æ•°æ®ç”¨äºåˆ†æ
                                    diagnosis_data.append({
                                        'patient1': patient1,
                                        'patient2': patient2,
                                        'diagnosis_type': diagnosis_type,
                                        'diagnosis': diagnosis_value
                                    })
                                    
                                    if patient1 not in nodes:
                                        net.add_node(patient1, label=patient1, color='#add8e6', size=30)
                                        nodes.add(patient1)
                                    if patient2 not in nodes:
                                        net.add_node(patient2, label=patient2, color='#add8e6', size=30)
                                        nodes.add(patient2)
                                        
                                    net.add_edge(patient1, patient2, 
                                               title=f"{diagnosis_type}: {diagnosis_value}",
                                               label=diagnosis_value)
                                
                                # ä¿å­˜å¹¶æ˜¾ç¤ºç½‘ç»œå›¾
                                with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.html', encoding='utf-8') as f:
                                    net.save_graph(f.name)
                                    with open(f.name, 'r', encoding='utf-8') as f:
                                        html_content = f.read()
                                    components.html(html_content, height=600)
                                    os.unlink(f.name)
                                
                                # ä½¿ç”¨å¤§æ¨¡å‹åˆ†æè¯Šæ–­å…³ç³»
                                if diagnosis_data:
                                    with st.spinner("æ­£åœ¨åˆ†æè¯Šæ–­å…³ç³»..."):
                                        # è·å–æ¯ä¸ªæ‚£è€…çš„å®Œæ•´è¯Šæ–­ä¿¡æ¯
                                        patient_diagnoses_query = """
                                        SELECT 
                                            e.ENTITY_NAME as patient_name,
                                            JSON_QUERY(e.ENTITY_VALUE, '$.ä¸»è¯‰ä¸è¯Šæ–­') as diagnoses
                                        FROM MEDICAL_ENTITIES e
                                        WHERE e.ENTITY_TYPE = 'æ‚£è€…'
                                        """
                                        patient_diagnoses_results = graph_store.execute_sql(patient_diagnoses_query)
                                        
                                        # æ„å»ºåˆ†ææ–‡æœ¬
                                        analysis_text = []
                                        for result in patient_diagnoses_results:
                                            patient_name = result['patient_name']
                                            diagnoses = json.loads(result['diagnoses'])
                                            
                                            analysis_text.append(f"\næ‚£è€… {patient_name}:")
                                            admission_diagnoses = []
                                            discharge_diagnoses = []
                                            
                                            for diag in diagnoses:
                                                if diag['ç±»å‹'] == 'å…¥é™¢è¯Šæ–­':
                                                    admission_diagnoses.append(diag['å†…å®¹'])
                                                elif diag['ç±»å‹'] == 'å‡ºé™¢è¯Šæ–­':
                                                    discharge_diagnoses.append(diag['å†…å®¹'])
                                            
                                            if admission_diagnoses:
                                                analysis_text.append("å…¥é™¢è¯Šæ–­ï¼š")
                                                for diag in admission_diagnoses:
                                                    analysis_text.append(f"- {diag}")
                                            
                                            if discharge_diagnoses:
                                                analysis_text.append("å‡ºé™¢è¯Šæ–­ï¼š")
                                                for diag in discharge_diagnoses:
                                                    analysis_text.append(f"- {diag}")
                                        
                                        # æ„å»ºæç¤ºè¯
                                        prompt = f"""
                                        è¯·åˆ†æä»¥ä¸‹æ‚£è€…ç¾¤ä½“çš„è¯Šæ–­å…³ç³»ç½‘ç»œï¼Œç»™å‡ºä¸“ä¸šçš„åŒ»å­¦åˆ†ææ„è§ã€‚
                                        è¯·åŒ…å«ä»¥ä¸‹æ–¹é¢ï¼š
                                        1. æ‚£è€…ç¾¤ä½“çš„ä¸»è¦è¯Šæ–­ç±»å‹åˆ†å¸ƒ
                                        2. å…¥é™¢è¯Šæ–­å’Œå‡ºé™¢è¯Šæ–­çš„å˜åŒ–åˆ†æ
                                        3. è¯Šæ–­ä¹‹é—´çš„å…³è”æ€§åˆ†æ
                                        4. å¯èƒ½çš„æ²»ç–—è·¯å¾„å’Œæ•ˆæœåˆ†æ
                                        5. å¯¹ä¸´åºŠè¯Šç–—çš„å»ºè®®

                                        æ‚£è€…è¯Šæ–­æ•°æ®ï¼š
                                        {chr(10).join(analysis_text)}

                                        è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€å›ç­”ã€‚
                                        """

                                        try:
                                            # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
                                            client = OpenAI(
                                                api_key=os.getenv("OPENAI_API_KEY"),
                                                base_url=os.getenv("OPENAI_API_BASE")
                                            )
                                            
                                            # è°ƒç”¨OpenAI APIè¿›è¡Œåˆ†æ
                                            response = client.chat.completions.create(
                                                model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
                                                messages=[
                                                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ä¸´åºŠåŒ»ç”Ÿï¼Œæ“…é•¿åˆ†ææ‚£è€…è¯Šæ–­å…³ç³»å’Œæ²»ç–—è·¯å¾„ã€‚"},
                                                    {"role": "user", "content": prompt}
                                                ],
                                                temperature=0.7
                                            )
                                            
                                            # æ˜¾ç¤ºåˆ†æç»“æœ
                                            st.write("### è¯Šæ–­å…³ç³»ç½‘ç»œåˆ†æ")
                                            st.markdown(response.choices[0].message.content)
                                        except Exception as e:
                                            logger.error("å¤§æ¨¡å‹åˆ†æå¤±è´¥: %s", str(e))
                                            st.error(f"åˆ†æå¤±è´¥: {str(e)}")
                                else:
                                    st.info("æœªæ‰¾åˆ°è¶³å¤Ÿçš„è¯Šæ–­æ•°æ®è¿›è¡Œåˆ†æ")
                            else:
                                st.info("æœªæ‰¾åˆ°è¯Šæ–­å…³ç³»")
                    except Exception as e:
                        st.error(f"åˆ†æå¤±è´¥: {str(e)}")
                        
        elif query_type == "æ‚£è€…ç”¨è¯å…³è”åˆ†æ":
            patient_name = st.selectbox("é€‰æ‹©æ‚£è€…", ["é©¬æŸæŸ", "å‘¨æŸæŸ", "åˆ˜æŸæŸ", "è’²æŸæŸ", "æ¨æŸæŸ"])
            if st.button("åˆ†æ"):
                with st.spinner("æ­£åœ¨åˆ†æç”¨è¯å…³è”..."):
                    try:
                        with OracleGraphStore() as graph_store:
                            # ä½¿ç”¨JSON_TABLEä»å®ä½“è¡¨ä¸­æå–ç”¨è¯ä¿¡æ¯
                            query = """
                            WITH MEDICATIONS AS (
                                SELECT 
                                    e.ENTITY_NAME as patient_name,
                                    m.è¯å“ as medication,
                                    m.ç”¨æ³• as usage,
                                    m.å‰‚é‡ as dosage
                                FROM MEDICAL_ENTITIES e,
                                     JSON_TABLE(e.ENTITY_VALUE, '$.ç”¨è¯è®°å½•[*]'
                                         COLUMNS (
                                             è¯å“ VARCHAR2(100) PATH '$.è¯å“',
                                             ç”¨æ³• VARCHAR2(100) PATH '$.ç”¨æ³•',
                                             å‰‚é‡ VARCHAR2(100) PATH '$.å‰‚é‡'
                                         )
                                     ) m
                                WHERE e.ENTITY_TYPE = 'æ‚£è€…'
                            )
                            SELECT DISTINCT 
                                m1.patient_name AS patient1,
                                m2.patient_name AS patient2,
                                m1.medication AS medication_name,
                                m1.usage AS medication_usage,
                                m1.dosage AS medication_dosage
                            FROM MEDICATIONS m1
                            JOIN MEDICATIONS m2 ON m1.medication = m2.medication
                                AND m1.patient_name = :patient_name
                                AND m1.patient_name != m2.patient_name
                            ORDER BY m1.patient_name, m2.patient_name, m1.medication
                            """
                            results = graph_store.execute_sql(query, {"patient_name": patient_name})
                            
                            if results:
                                st.success(f"æ‰¾åˆ° {len(results)} ä¸ªç”¨è¯å…³è”")
                                
                                # åˆ›å»ºç½‘ç»œå›¾
                                net = Network(height="600px", width="100%", bgcolor="#ffffff", font_color="black")
                                
                                # è®¾ç½®ç‰©ç†å¸ƒå±€é€‰é¡¹
                                net.set_options("""
                                {
                                    "nodes": {
                                        "font": {
                                            "size": 16,
                                            "face": "Microsoft YaHei"
                                        }
                                    },
                                    "edges": {
                                        "color": {
                                            "color": "#666666",
                                            "highlight": "#000000"
                                        },
                                        "font": {
                                            "size": 12,
                                            "face": "Microsoft YaHei"
                                        }
                                    },
                                    "physics": {
                                        "enabled": true,
                                        "solver": "forceAtlas2Based",
                                        "forceAtlas2Based": {
                                            "gravitationalConstant": -50,
                                            "centralGravity": 0.01,
                                            "springLength": 200,
                                            "springConstant": 0.08,
                                            "damping": 0.4,
                                            "avoidOverlap": 0.5
                                        }
                                    }
                                }
                                """)
                                
                                # æ·»åŠ èŠ‚ç‚¹å’Œè¾¹
                                nodes = set()
                                medication_data = []
                                
                                for result in results:
                                    patient1 = result['patient1']
                                    patient2 = result['patient2']
                                    medication = result['medication_name']
                                    usage = result.get('medication_usage', '')
                                    dosage = result.get('medication_dosage', '')
                                    
                                    # æ”¶é›†ç”¨è¯æ•°æ®ç”¨äºåˆ†æ
                                    medication_data.append({
                                        'patient1': patient1,
                                        'patient2': patient2,
                                        'medication': medication,
                                        'usage': usage,
                                        'dosage': dosage
                                    })
                                    
                                    if patient1 not in nodes:
                                        net.add_node(patient1, label=patient1, color='#add8e6', size=30)
                                        nodes.add(patient1)
                                    if patient2 not in nodes:
                                        net.add_node(patient2, label=patient2, color='#add8e6', size=30)
                                        nodes.add(patient2)
                                        
                                    edge_label = f"{medication}"
                                    if usage and dosage:
                                        edge_title = f"{medication}\nç”¨æ³•ï¼š{usage}\nå‰‚é‡ï¼š{dosage}"
                                    else:
                                        edge_title = medication
                                        
                                    net.add_edge(patient1, patient2, 
                                               title=edge_title,
                                               label=edge_label)
                                
                                # ä¿å­˜å¹¶æ˜¾ç¤ºç½‘ç»œå›¾
                                with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.html', encoding='utf-8') as f:
                                    net.save_graph(f.name)
                                    with open(f.name, 'r', encoding='utf-8') as f:
                                        html_content = f.read()
                                    components.html(html_content, height=600)
                                    os.unlink(f.name)
                                
                                # ä½¿ç”¨å¤§æ¨¡å‹åˆ†æç”¨è¯å…³è”
                                if medication_data:
                                    with st.spinner("æ­£åœ¨åˆ†æç”¨è¯å…³è”..."):
                                        # è·å–æ¯ä¸ªæ‚£è€…çš„å®Œæ•´ç”¨è¯ä¿¡æ¯
                                        patient_medications_query = """
                                        SELECT 
                                            e.ENTITY_NAME as patient_name,
                                            JSON_QUERY(e.ENTITY_VALUE, '$.ç”¨è¯è®°å½•') as medications
                                        FROM MEDICAL_ENTITIES e
                                        WHERE e.ENTITY_TYPE = 'æ‚£è€…'
                                        """
                                        patient_medications_results = graph_store.execute_sql(patient_medications_query)
                                        
                                        # æ„å»ºåˆ†ææ–‡æœ¬
                                        analysis_text = []
                                        for result in patient_medications_results:
                                            patient_name = result['patient_name']
                                            medications = json.loads(result['medications'] or '[]')
                                            
                                            if medications:
                                                analysis_text.append(f"\næ‚£è€… {patient_name} çš„ç”¨è¯è®°å½•ï¼š")
                                                for med in medications:
                                                    med_text = f"- {med['è¯å“']}"
                                                    if 'ç”¨æ³•' in med:
                                                        med_text += f"ï¼ˆ{med['ç”¨æ³•']}"
                                                        if 'å‰‚é‡' in med:
                                                            med_text += f"ï¼Œ{med['å‰‚é‡']}"
                                                        med_text += "ï¼‰"
                                                    analysis_text.append(med_text)
                                        
                                        # æ„å»ºæç¤ºè¯
                                        prompt = f"""
                                        è¯·åˆ†æä»¥ä¸‹æ‚£è€…ç¾¤ä½“çš„ç”¨è¯å…³è”æƒ…å†µï¼Œç»™å‡ºä¸“ä¸šçš„åŒ»å­¦åˆ†ææ„è§ã€‚
                                        è¯·åŒ…å«ä»¥ä¸‹æ–¹é¢ï¼š
                                        1. æ‚£è€…ç¾¤ä½“çš„ä¸»è¦ç”¨è¯ç±»å‹åˆ†å¸ƒ
                                        2. è¯ç‰©ä¹‹é—´çš„ç›¸äº’ä½œç”¨åˆ†æ
                                        3. ç”¨è¯æ–¹æ¡ˆçš„åˆç†æ€§åˆ†æ
                                        4. å¯èƒ½çš„ç”¨è¯é£é™©æç¤º
                                        5. å¯¹ä¸´åºŠç”¨è¯çš„å»ºè®®

                                        æ‚£è€…ç”¨è¯æ•°æ®ï¼š
                                        {chr(10).join(analysis_text)}

                                        è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€å›ç­”ã€‚
                                        """

                                        try:
                                            # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
                                            client = OpenAI(
                                                api_key=os.getenv("OPENAI_API_KEY"),
                                                base_url=os.getenv("OPENAI_API_BASE")
                                            )
                                            
                                            # è°ƒç”¨OpenAI APIè¿›è¡Œåˆ†æ
                                            response = client.chat.completions.create(
                                                model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
                                                messages=[
                                                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ä¸´åºŠè¯å¸ˆï¼Œæ“…é•¿åˆ†ææ‚£è€…ç”¨è¯æ–¹æ¡ˆå’Œè¯ç‰©ç›¸äº’ä½œç”¨ã€‚"},
                                                    {"role": "user", "content": prompt}
                                                ],
                                                temperature=0.7
                                            )
                                            
                                            # æ˜¾ç¤ºåˆ†æç»“æœ
                                            st.write("### ç”¨è¯å…³è”åˆ†æ")
                                            st.markdown(response.choices[0].message.content)
                                        except Exception as e:
                                            logger.error("å¤§æ¨¡å‹åˆ†æå¤±è´¥: %s", str(e))
                                            st.error(f"åˆ†æå¤±è´¥: {str(e)}")
                                else:
                                    st.info("æœªæ‰¾åˆ°è¶³å¤Ÿçš„ç”¨è¯æ•°æ®è¿›è¡Œåˆ†æ")
                            else:
                                st.info("æœªæ‰¾åˆ°ç”¨è¯å…³è”")
                    except Exception as e:
                        logger.error("åˆ†æå¤±è´¥: %s", str(e))
                        st.error(f"åˆ†æå¤±è´¥: {str(e)}")
                        
        elif query_type == "æ‚£è€…æ²»ç–—æ–¹æ¡ˆå¯¹æ¯”":
            patient1 = st.selectbox("é€‰æ‹©ç¬¬ä¸€ä¸ªæ‚£è€…", ["é©¬æŸæŸ", "å‘¨æŸæŸ", "åˆ˜æŸæŸ", "è’²æŸæŸ", "æ¨æŸæŸ"])
            patient2 = st.selectbox("é€‰æ‹©ç¬¬äºŒä¸ªæ‚£è€…", ["é©¬æŸæŸ", "å‘¨æŸæŸ", "åˆ˜æŸæŸ", "è’²æŸæŸ", "æ¨æŸæŸ"])
            if patient1 != patient2 and st.button("å¯¹æ¯”"):
                with st.spinner("æ­£åœ¨å¯¹æ¯”æ²»ç–—æ–¹æ¡ˆ..."):
                    try:
                        with OracleGraphStore() as graph_store:
                            # ä½¿ç”¨PGQLæŸ¥è¯¢æ²»ç–—æ–¹æ¡ˆ
                            query = """
                            SELECT 
                                v.entity_name AS patient,
                                e.relation_type AS treatment_type,
                                t.entity_value AS treatment_detail
                            MATCH (v) -[e]-> (t)
                            WHERE v.entity_type = 'PATIENT'
                              AND v.entity_name IN (:patient1, :patient2)
                              AND e.relation_type = 'è¯Šç–—ç»è¿‡'
                            """
                            results = graph_store.execute_pgql(query, {
                                "patient1": patient1,
                                "patient2": patient2
                            })
                            
                            if results:
                                # æŒ‰æ‚£è€…åˆ†ç»„æ²»ç–—æ–¹æ¡ˆ
                                treatments = {}
                                for result in results:
                                    patient = result['patient']
                                    if patient not in treatments:
                                        treatments[patient] = []
                                    treatments[patient].append({
                                        'treatment': result['treatment_detail'],
                                        'effect': result['effect']
                                    })
                                
                                # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.subheader(patient1)
                                    if patient1 in treatments:
                                        for t in treatments[patient1]:
                                            st.write(f"- {t['treatment']} (æ•ˆæœ: {t['effect']})")
                                    else:
                                        st.info("æ— æ²»ç–—æ–¹æ¡ˆè®°å½•")
                                        
                                with col2:
                                    st.subheader(patient2)
                                    if patient2 in treatments:
                                        for t in treatments[patient2]:
                                            st.write(f"- {t['treatment']} (æ•ˆæœ: {t['effect']})")
                                    else:
                                        st.info("æ— æ²»ç–—æ–¹æ¡ˆè®°å½•")
                            else:
                                st.info("æœªæ‰¾åˆ°æ²»ç–—æ–¹æ¡ˆè®°å½•")
                    except Exception as e:
                        st.error(f"å¯¹æ¯”å¤±è´¥: {str(e)}")
    
    with tab2:
        st.subheader("è‡ªå®šä¹‰PGQLæŸ¥è¯¢")
        st.markdown("""
        æ‚¨å¯ä»¥è¾“å…¥è‡ªå®šä¹‰çš„PGQLæŸ¥è¯¢è¯­å¥ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ç¤ºä¾‹ï¼š
        
        1. æŸ¥è¯¢æ‚£è€…çš„æ‰€æœ‰ç—‡çŠ¶ï¼š
        ```sql
        SELECT *
        FROM GRAPH_TABLE ( MEDICAL_KG
            MATCH (v) -[e]-> (s)
            WHERE v.ENTITY_TYPE = 'æ‚£è€…'
            AND v.ENTITY_NAME = 'å¼ æŸæŸ'
            AND e.RELATION_TYPE = 'ç°ç—…å²'
            COLUMNS (
                v.ENTITY_NAME AS patient_name,
                JSON_VALUE(s.ENTITY_VALUE, '$.ç—‡çŠ¶') AS symptom
            )
        )
        ```
        
        2. æŸ¥è¯¢æ‰€æœ‰æœ‰å‘çƒ­ç—‡çŠ¶çš„æ‚£è€…ï¼š
        ```sql
        SELECT *
        FROM GRAPH_TABLE ( MEDICAL_KG
            MATCH (v) -[e]-> (s)
            WHERE v.ENTITY_TYPE = 'æ‚£è€…'
            AND e.RELATION_TYPE = 'ç°ç—…å²'
            AND JSON_EXISTS(s.ENTITY_VALUE, '$.ç—‡çŠ¶?(@ like_regex "å‘çƒ­" flag "i")')
            COLUMNS (
                v.ENTITY_NAME AS patient_name,
                JSON_VALUE(s.ENTITY_VALUE, '$.ç—‡çŠ¶') AS symptom
            )
        )
        ```
        
        3. æŸ¥è¯¢æ‚£è€…çš„å¼‚å¸¸ç”ŸåŒ–æŒ‡æ ‡ï¼š
        ```sql
        SELECT *
        FROM GRAPH_TABLE ( MEDICAL_KG
            MATCH (v) -[e]-> (s)
            WHERE v.ENTITY_TYPE = 'æ‚£è€…'
            AND v.ENTITY_NAME = 'å¼ æŸæŸ'
            AND e.RELATION_TYPE = 'ç”ŸåŒ–æŒ‡æ ‡'
            AND JSON_EXISTS(s.ENTITY_VALUE, '$.å‚è€ƒèŒƒå›´?(@ == "å¼‚å¸¸")')
            COLUMNS (
                v.ENTITY_NAME AS patient_name,
                JSON_VALUE(s.ENTITY_VALUE, '$.é¡¹ç›®') AS indicator,
                JSON_VALUE(s.ENTITY_VALUE, '$.ç»“æœ') AS value,
                JSON_VALUE(s.ENTITY_VALUE, '$.å•ä½') AS unit,
                JSON_VALUE(s.ENTITY_VALUE, '$.å‚è€ƒèŒƒå›´') AS reference
            )
        )
        ```
        
        4. æŸ¥è¯¢å…·æœ‰ç›¸ä¼¼ç—‡çŠ¶çš„æ‚£è€…ï¼š
        ```sql
        SELECT *
        FROM GRAPH_TABLE ( MEDICAL_KG
            MATCH (v1) -[e1]-> (s1), (v2) -[e2]-> (s2)
            WHERE v1.ENTITY_TYPE = 'æ‚£è€…'
            AND v2.ENTITY_TYPE = 'æ‚£è€…'
            AND v1.ENTITY_NAME != v2.ENTITY_NAME
            AND e1.RELATION_TYPE = 'ç°ç—…å²'
            AND e2.RELATION_TYPE = 'ç°ç—…å²'
            AND JSON_VALUE(s1.ENTITY_VALUE, '$.ç—‡çŠ¶') = JSON_VALUE(s2.ENTITY_VALUE, '$.ç—‡çŠ¶')
            COLUMNS (
                v1.ENTITY_NAME AS patient1,
                v2.ENTITY_NAME AS patient2,
                JSON_VALUE(s1.ENTITY_VALUE, '$.ç—‡çŠ¶') AS common_symptom
            )
        )
        ```
        
        5. æŸ¥è¯¢æ‚£è€…çš„è¯Šæ–­å’Œç›¸å…³ç—‡çŠ¶ï¼š
        ```sql
        SELECT *
        FROM GRAPH_TABLE ( MEDICAL_KG
            MATCH (v) -[e1]-> (d), (v) -[e2]-> (s)
            WHERE v.ENTITY_TYPE = 'æ‚£è€…'
            AND v.ENTITY_NAME = 'å¼ æŸæŸ'
            AND e1.RELATION_TYPE = 'è¯Šæ–­'
            AND e2.RELATION_TYPE = 'ç°ç—…å²'
            COLUMNS (
                v.ENTITY_NAME AS patient_name,
                JSON_VALUE(d.ENTITY_VALUE, '$.ç±»å‹') AS diagnosis_type,
                JSON_VALUE(d.ENTITY_VALUE, '$.å†…å®¹') AS diagnosis,
                JSON_VALUE(s.ENTITY_VALUE, '$.ç—‡çŠ¶') AS symptom
            )
        )
        ```
        """)
        
        query = st.text_area("è¾“å…¥PGQLæŸ¥è¯¢è¯­å¥", height=150)
        params = st.text_input("è¾“å…¥å‚æ•°ï¼ˆJSONæ ¼å¼ï¼Œå¯é€‰ï¼‰", "{}")
        
        if st.button("æ‰§è¡ŒæŸ¥è¯¢"):
            if query:
                with st.spinner("æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢..."):
                    try:
                        # è§£æå‚æ•°
                        try:
                            params = json.loads(params) if params.strip() else {}
                        except json.JSONDecodeError:
                            st.error("å‚æ•°æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨æœ‰æ•ˆçš„JSONæ ¼å¼")
                            return
                        
                        # æ‰§è¡ŒæŸ¥è¯¢
                        with OracleGraphStore() as graph_store:
                            results = graph_store.execute_pgql(query, params)
                            if results:
                                st.success(f"æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {len(results)} æ¡ç»“æœ")
                                st.json(results)
                            else:
                                st.info("æŸ¥è¯¢æœªè¿”å›ä»»ä½•ç»“æœ")
                    except Exception as e:
                        st.error(f"æŸ¥è¯¢å¤±è´¥: {str(e)}")
            else:
                st.warning("è¯·è¾“å…¥æŸ¥è¯¢è¯­å¥")

def analyze_medication():
    query = """
    WITH PATIENT_MEDS AS (
        SELECT 
            e.entity_name as patient_name,
            j.content as treatment_content
        FROM MEDICAL_ENTITIES e,
        JSON_TABLE(e.entity_value, '$.è¯Šç–—ç»è¿‡[*]' 
            COLUMNS (
                content PATH '$.å†…å®¹'
            )
        ) j
        WHERE e.entity_type = 'æ‚£è€…'
        AND REGEXP_LIKE(j.content, 'ç»™äºˆ|ä½¿ç”¨|æœç”¨|æ²»ç–—|ç”¨è¯', 'i')
    )
    SELECT 
        patient_name,
        treatment_content,
        COUNT(*) OVER (PARTITION BY treatment_content) as usage_count
    FROM PATIENT_MEDS
    ORDER BY usage_count DESC, patient_name
    """
    
    results = execute_sql(query)
    
    if not results:
        st.warning("æœªæ‰¾åˆ°ç”¨è¯è®°å½•æ•°æ®ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºï¼š\n1. æ•°æ®ä¸­æ²¡æœ‰è®°å½•ç”¨è¯ä¿¡æ¯\n2. ç”¨è¯ä¿¡æ¯çš„è®°å½•æ ¼å¼éœ€è¦æ ‡å‡†åŒ–")
        return
        
    # å±•ç¤ºç”¨è¯åˆ†æç»“æœ
    st.subheader("æ‚£è€…ç”¨è¯åˆ†æ")
    
    # åˆ›å»ºæ•°æ®è¡¨æ ¼
    df = pd.DataFrame(results, columns=['æ‚£è€…å§“å', 'ç”¨è¯è®°å½•', 'ä½¿ç”¨é¢‘æ¬¡'])
    
    # æ˜¾ç¤ºè¯¦ç»†æ•°æ®è¡¨æ ¼
    st.dataframe(df)
    
    # ä½¿ç”¨plotlyåˆ›å»ºå¯è§†åŒ–å›¾è¡¨
    fig = px.bar(df, 
                 x='ç”¨è¯è®°å½•', 
                 y='ä½¿ç”¨é¢‘æ¬¡',
                 title='ç”¨è¯é¢‘æ¬¡åˆ†å¸ƒ',
                 color='ä½¿ç”¨é¢‘æ¬¡',
                 hover_data=['æ‚£è€…å§“å'])
    
    fig.update_layout(
        xaxis_title="ç”¨è¯è®°å½•",
        yaxis_title="ä½¿ç”¨é¢‘æ¬¡",
        showlegend=True
    )
    
    st.plotly_chart(fig)
    
    # æ·»åŠ AIåˆ†æè§è§£
    st.subheader("AIåˆ†æè§è§£")
    
    # è®¡ç®—ä¸€äº›åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    total_patients = len(df['æ‚£è€…å§“å'].unique())
    total_medications = len(df['ç”¨è¯è®°å½•'].unique())
    most_common_med = df.loc[df['ä½¿ç”¨é¢‘æ¬¡'].idxmax(), 'ç”¨è¯è®°å½•']
    
    analysis_text = f"""
    æ ¹æ®æ•°æ®åˆ†æï¼Œå‘ç°ä»¥ä¸‹ä¸»è¦ç‰¹ç‚¹ï¼š
    
    1. å…±æœ‰{total_patients}ä½æ‚£è€…çš„ç”¨è¯è®°å½•
    2. è®°å½•ä¸­åŒ…å«{total_medications}ç§ä¸åŒçš„æ²»ç–—æ–¹æ¡ˆ
    3. æœ€å¸¸è§çš„æ²»ç–—æ–¹æ¡ˆæ˜¯"{most_common_med}"
    
    å»ºè®®ï¼š
    - è¿›ä¸€æ­¥ç»†åŒ–ç”¨è¯è®°å½•çš„åˆ†ç±»
    - æ ‡å‡†åŒ–ç”¨è¯è®°å½•çš„æ ¼å¼
    - æ·»åŠ è¯ç‰©å‰‚é‡ã€ç”¨è¯æ—¶é—´ç­‰è¯¦ç»†ä¿¡æ¯
    """
    
    st.markdown(analysis_text)

def main():
    st.title("åŸºäºOracle 23AIç”µå­ç—…å†æ£€ç´¢ç³»ç»Ÿ", anchor=False)
    st.markdown("<div style='text-align: right'>Developed by Huaiyuan Tan</div>", unsafe_allow_html=True)
    
    # åˆå§‹åŒ–æ•°æ®åº“
    init_database()
    
    # åˆ›å»ºä¾§è¾¹æ èœå•
    menu = st.sidebar.selectbox(
        "åŠŸèƒ½èœå•",
        ["æ–‡æ¡£ç®¡ç†", "å›¾æ•°æ®æ£€ç´¢", "å‘é‡æ£€ç´¢", "ç»“æ„åŒ–æ£€ç´¢", "å±æ€§å›¾æ£€ç´¢"]
    )
    
    if menu == "æ–‡æ¡£ç®¡ç†":
        display_document_management()
    elif menu == "å›¾æ•°æ®æ£€ç´¢":
        st.header("å›¾æ•°æ®æ£€ç´¢")
        # æ˜¾ç¤ºå·²è§£æçš„æ–‡æ¡£
        display_parsed_documents()
        
        # æ·»åŠ æœç´¢æ¡†
        query = st.text_input("è¯·è¾“å…¥æœç´¢å†…å®¹ï¼ˆæ”¯æŒæŒ‰æ‚£è€…å§“åã€ç—‡çŠ¶ã€è¯Šæ–­ç­‰æœç´¢ï¼‰")
        if query:
            results = search_graph_data(query)
            display_graph_results(results, query)
    elif menu == "å‘é‡æ£€ç´¢":
        display_vector_search()
    elif menu == "å±æ€§å›¾æ£€ç´¢":
        display_property_graph_search()
    else:  # ç»“æ„åŒ–æ£€ç´¢
        display_structured_search()

class FileObject:
    """æ–‡ä»¶å¯¹è±¡åŒ…è£…ç±»ï¼Œæä¾›ç»Ÿä¸€çš„æ–‡ä»¶æ“ä½œæ¥å£"""
    def __init__(self, path):
        """åˆå§‹åŒ–æ–‡ä»¶å¯¹è±¡
        
        Args:
            path: æ–‡ä»¶è·¯å¾„ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ– Path å¯¹è±¡
        """
        self.path = Path(path)
        self.name = self.path.name
        self._file = None
        
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åè®¾ç½®ç±»å‹
        self.type = "application/pdf" if self.path.suffix.lower() == '.pdf' else "text/plain"
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not self.path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {self.path}")
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å¯è¯»
        if not os.access(self.path, os.R_OK):
            raise PermissionError(f"æ–‡ä»¶æ— æ³•è¯»å–: {self.path}")
            
        logger.debug(f"åˆ›å»ºæ–‡ä»¶å¯¹è±¡: {self.path}, ç±»å‹: {self.type}")
    
    def read(self):
        """è¯»å–æ–‡ä»¶å†…å®¹
        
        Returns:
            bytes: æ–‡ä»¶çš„äºŒè¿›åˆ¶å†…å®¹
        """
        try:
            if self._file is None:
                self._file = open(self.path, 'rb')
            return self._file.read()
        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
            raise
    
    def seek(self, pos):
        """ç§»åŠ¨æ–‡ä»¶æŒ‡é’ˆåˆ°æŒ‡å®šä½ç½®
        
        Args:
            pos: ç›®æ ‡ä½ç½®ï¼ˆå­—èŠ‚åç§»é‡ï¼‰
        """
        try:
            if self._file is not None:
                self._file.seek(pos)
        except Exception as e:
            logger.error(f"ç§»åŠ¨æ–‡ä»¶æŒ‡é’ˆå¤±è´¥: {str(e)}")
            raise
    
    def close(self):
        """å…³é—­æ–‡ä»¶"""
        try:
            if self._file is not None:
                self._file.close()
                self._file = None
                logger.debug(f"å…³é—­æ–‡ä»¶: {self.path}")
        except Exception as e:
            logger.error(f"å…³é—­æ–‡ä»¶å¤±è´¥: {str(e)}")
            raise
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        self.close()
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿æ–‡ä»¶è¢«å…³é—­"""
        self.close()

if __name__ == "__main__":
    main()

